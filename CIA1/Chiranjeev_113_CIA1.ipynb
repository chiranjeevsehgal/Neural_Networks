{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1:**\n",
        "\n",
        "# Part II: XOR Gate Implementation"
      ],
      "metadata": {
        "id": "4mq_2F026FY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. XOR Truth Table Dataset:**"
      ],
      "metadata": {
        "id": "fsuF6MIj6Oyu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OlfEYLb6ywpw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# XOR gate truth table\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Inputs\n",
        "y = np.array([0, 1, 1, 0])  # XOR output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Single-Layer Perceptron Implementation:**"
      ],
      "metadata": {
        "id": "0ppAgl7i6Syt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Create a simple perceptron model\n",
        "single_layer_model = Sequential()\n",
        "single_layer_model.add(Dense(1, input_dim=2, activation='hard_sigmoid'))  # Single layer\n",
        "\n",
        "# Compile the model\n",
        "single_layer_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the perceptron on the XOR data\n",
        "single_layer_model.fit(X, y, epochs=100, verbose=1)\n",
        "\n",
        "# Evaluate the performance\n",
        "loss, accuracy = single_layer_model.evaluate(X, y)\n",
        "print(f'Single Layer Perceptron Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBy0eca_6Tjk",
        "outputId": "a9616a9b-b1d7-4054-fd6c-5b625ea160e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728ms/step - accuracy: 0.7500 - loss: 0.7305\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.7304\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7302\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.7301\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.7299\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7298\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 0.7296\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.7295\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.7293\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.7291\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.7290\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7288\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.7287\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.7285\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7284\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7282\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.7281\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 0.7279\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7278\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7277\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7275\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.7274\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7272\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7271\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.7269\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.7268\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7267\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7265\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7264\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 0.7262\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.7261\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7260\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7258\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7257\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7256\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7254\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7253\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.7252\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7250\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7249\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7248\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7246\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7245\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7244\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7242\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7241\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7240\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7239\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7237\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7236\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7235\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7234\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7232\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7231\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7230\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7229\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7228\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7226\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7225\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.7224\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7223\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7222\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7221\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7219\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 0.7218\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 0.7217\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.7216\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7215\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7214\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.7213\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 0.7212\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7211\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.7209\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.7208\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 0.7207\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.7206\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.7205\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.7204\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7203\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7202\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7201\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.7200\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7199\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.7198\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7197\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7196\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.7195\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 0.7194\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7193\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.7192\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7191\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7190\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7189\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7188\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7187\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7186\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.7185\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7184\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7183\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.7182\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5000 - loss: 0.7182\n",
            "Single Layer Perceptron Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations for Single-Layer Perceptron:**\n",
        "\n",
        "The model will struggle to converge because XOR is not linearly separable, and the perceptron will not achieve a high accuracy."
      ],
      "metadata": {
        "id": "_SPz6fQh6afA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Multi-Layer Perceptron (MLP) Implementation:**"
      ],
      "metadata": {
        "id": "AmS0zSVf6jNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Multi-Layer Perceptron model with a hidden layer\n",
        "mlp_model = Sequential()\n",
        "mlp_model.add(Dense(2, input_dim=2, activation='relu'))  # Hidden layer with 2 neurons\n",
        "mlp_model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "mlp_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "mlp_model.fit(X, y, epochs=500, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = mlp_model.evaluate(X, y)\n",
        "print(f'Multi-Layer Perceptron Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbnNv_qw6c6X",
        "outputId": "3e35ecb3-a76d-47e2-af98-1c2b114881cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5000 - loss: 0.6892\n",
            "Epoch 2/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.6891\n",
            "Epoch 3/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5000 - loss: 0.6889\n",
            "Epoch 4/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5000 - loss: 0.6887\n",
            "Epoch 5/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5000 - loss: 0.6886\n",
            "Epoch 6/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5000 - loss: 0.6884\n",
            "Epoch 7/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.5000 - loss: 0.6883\n",
            "Epoch 8/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.5000 - loss: 0.6881\n",
            "Epoch 9/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5000 - loss: 0.6880\n",
            "Epoch 10/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6878\n",
            "Epoch 11/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5000 - loss: 0.6877\n",
            "Epoch 12/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6876\n",
            "Epoch 13/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.6874\n",
            "Epoch 14/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 0.6873\n",
            "Epoch 15/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5000 - loss: 0.6871\n",
            "Epoch 16/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.6870\n",
            "Epoch 17/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 0.6869\n",
            "Epoch 18/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6867\n",
            "Epoch 19/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6866\n",
            "Epoch 20/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6864\n",
            "Epoch 21/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6863\n",
            "Epoch 22/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6862\n",
            "Epoch 23/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7500 - loss: 0.6860\n",
            "Epoch 24/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7500 - loss: 0.6859\n",
            "Epoch 25/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6858\n",
            "Epoch 26/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6856\n",
            "Epoch 27/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6855\n",
            "Epoch 28/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7500 - loss: 0.6854\n",
            "Epoch 29/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6852\n",
            "Epoch 30/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6851\n",
            "Epoch 31/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7500 - loss: 0.6850\n",
            "Epoch 32/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7500 - loss: 0.6848\n",
            "Epoch 33/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7500 - loss: 0.6847\n",
            "Epoch 34/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7500 - loss: 0.6846\n",
            "Epoch 35/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7500 - loss: 0.6844\n",
            "Epoch 36/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6843\n",
            "Epoch 37/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6842\n",
            "Epoch 38/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7500 - loss: 0.6840\n",
            "Epoch 39/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7500 - loss: 0.6839\n",
            "Epoch 40/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7500 - loss: 0.6838\n",
            "Epoch 41/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7500 - loss: 0.6836\n",
            "Epoch 42/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7500 - loss: 0.6835\n",
            "Epoch 43/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7500 - loss: 0.6834\n",
            "Epoch 44/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7500 - loss: 0.6832\n",
            "Epoch 45/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6831\n",
            "Epoch 46/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6830\n",
            "Epoch 47/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6828\n",
            "Epoch 48/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6827\n",
            "Epoch 49/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7500 - loss: 0.6826\n",
            "Epoch 50/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7500 - loss: 0.6824\n",
            "Epoch 51/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6823\n",
            "Epoch 52/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6822\n",
            "Epoch 53/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6820\n",
            "Epoch 54/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6819\n",
            "Epoch 55/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6818\n",
            "Epoch 56/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6816\n",
            "Epoch 57/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6815\n",
            "Epoch 58/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6813\n",
            "Epoch 59/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6812\n",
            "Epoch 60/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7500 - loss: 0.6811\n",
            "Epoch 61/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6809\n",
            "Epoch 62/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6808\n",
            "Epoch 63/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6807\n",
            "Epoch 64/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6805\n",
            "Epoch 65/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6804\n",
            "Epoch 66/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6803\n",
            "Epoch 67/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6801\n",
            "Epoch 68/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6800\n",
            "Epoch 69/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6799\n",
            "Epoch 70/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6797\n",
            "Epoch 71/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6796\n",
            "Epoch 72/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6795\n",
            "Epoch 73/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7500 - loss: 0.6793\n",
            "Epoch 74/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7500 - loss: 0.6792\n",
            "Epoch 75/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6790\n",
            "Epoch 76/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6789\n",
            "Epoch 77/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6788\n",
            "Epoch 78/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6786\n",
            "Epoch 79/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6785\n",
            "Epoch 80/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6784\n",
            "Epoch 81/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6782\n",
            "Epoch 82/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6781\n",
            "Epoch 83/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6779\n",
            "Epoch 84/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6778\n",
            "Epoch 85/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6777\n",
            "Epoch 86/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6775\n",
            "Epoch 87/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6774\n",
            "Epoch 88/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6772\n",
            "Epoch 89/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7500 - loss: 0.6771\n",
            "Epoch 90/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6770\n",
            "Epoch 91/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6768\n",
            "Epoch 92/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.6767\n",
            "Epoch 93/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6765\n",
            "Epoch 94/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6764\n",
            "Epoch 95/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6762\n",
            "Epoch 96/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6761\n",
            "Epoch 97/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6760\n",
            "Epoch 98/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7500 - loss: 0.6758\n",
            "Epoch 99/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7500 - loss: 0.6757\n",
            "Epoch 100/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6755\n",
            "Epoch 101/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6754\n",
            "Epoch 102/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6752\n",
            "Epoch 103/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6751\n",
            "Epoch 104/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.6750\n",
            "Epoch 105/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6748\n",
            "Epoch 106/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6747\n",
            "Epoch 107/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6745\n",
            "Epoch 108/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6744\n",
            "Epoch 109/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6742\n",
            "Epoch 110/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6741\n",
            "Epoch 111/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6739\n",
            "Epoch 112/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6738\n",
            "Epoch 113/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6736\n",
            "Epoch 114/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6735\n",
            "Epoch 115/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6733\n",
            "Epoch 116/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6732\n",
            "Epoch 117/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6730\n",
            "Epoch 118/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6729\n",
            "Epoch 119/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6727\n",
            "Epoch 120/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6726\n",
            "Epoch 121/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6724\n",
            "Epoch 122/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6723\n",
            "Epoch 123/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6721\n",
            "Epoch 124/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6720\n",
            "Epoch 125/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7500 - loss: 0.6718\n",
            "Epoch 126/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7500 - loss: 0.6716\n",
            "Epoch 127/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7500 - loss: 0.6715\n",
            "Epoch 128/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6713\n",
            "Epoch 129/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6712\n",
            "Epoch 130/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6710\n",
            "Epoch 131/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.6709\n",
            "Epoch 132/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6707\n",
            "Epoch 133/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.6705\n",
            "Epoch 134/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6704\n",
            "Epoch 135/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6702\n",
            "Epoch 136/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6701\n",
            "Epoch 137/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6699\n",
            "Epoch 138/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6697\n",
            "Epoch 139/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7500 - loss: 0.6696\n",
            "Epoch 140/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6694\n",
            "Epoch 141/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6692\n",
            "Epoch 142/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6691\n",
            "Epoch 143/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6689\n",
            "Epoch 144/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6687\n",
            "Epoch 145/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6686\n",
            "Epoch 146/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6684\n",
            "Epoch 147/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6682\n",
            "Epoch 148/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6681\n",
            "Epoch 149/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6679\n",
            "Epoch 150/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6677\n",
            "Epoch 151/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7500 - loss: 0.6676\n",
            "Epoch 152/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6674\n",
            "Epoch 153/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7500 - loss: 0.6672\n",
            "Epoch 154/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6670\n",
            "Epoch 155/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6669\n",
            "Epoch 156/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6667\n",
            "Epoch 157/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6665\n",
            "Epoch 158/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.6663\n",
            "Epoch 159/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6662\n",
            "Epoch 160/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6660\n",
            "Epoch 161/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6658\n",
            "Epoch 162/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.6656\n",
            "Epoch 163/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6655\n",
            "Epoch 164/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6653\n",
            "Epoch 165/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6651\n",
            "Epoch 166/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6649\n",
            "Epoch 167/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6648\n",
            "Epoch 168/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7500 - loss: 0.6646\n",
            "Epoch 169/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6644\n",
            "Epoch 170/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6642\n",
            "Epoch 171/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6640\n",
            "Epoch 172/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6639\n",
            "Epoch 173/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6637\n",
            "Epoch 174/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6635\n",
            "Epoch 175/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6633\n",
            "Epoch 176/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6631\n",
            "Epoch 177/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6629\n",
            "Epoch 178/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6628\n",
            "Epoch 179/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 0.6626\n",
            "Epoch 180/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6624\n",
            "Epoch 181/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6622\n",
            "Epoch 182/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6620\n",
            "Epoch 183/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6618\n",
            "Epoch 184/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6616\n",
            "Epoch 185/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6615\n",
            "Epoch 186/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6612\n",
            "Epoch 187/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6611\n",
            "Epoch 188/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7500 - loss: 0.6609\n",
            "Epoch 189/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7500 - loss: 0.6607\n",
            "Epoch 190/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6605\n",
            "Epoch 191/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7500 - loss: 0.6603\n",
            "Epoch 192/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7500 - loss: 0.6601\n",
            "Epoch 193/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7500 - loss: 0.6599\n",
            "Epoch 194/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7500 - loss: 0.6597\n",
            "Epoch 195/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7500 - loss: 0.6595\n",
            "Epoch 196/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7500 - loss: 0.6594\n",
            "Epoch 197/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6592\n",
            "Epoch 198/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6590\n",
            "Epoch 199/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6588\n",
            "Epoch 200/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6586\n",
            "Epoch 201/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6584\n",
            "Epoch 202/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6582\n",
            "Epoch 203/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6580\n",
            "Epoch 204/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6578\n",
            "Epoch 205/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6576\n",
            "Epoch 206/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6574\n",
            "Epoch 207/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6572\n",
            "Epoch 208/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6570\n",
            "Epoch 209/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6569\n",
            "Epoch 210/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6567\n",
            "Epoch 211/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6565\n",
            "Epoch 212/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6563\n",
            "Epoch 213/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6561\n",
            "Epoch 214/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6559\n",
            "Epoch 215/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6557\n",
            "Epoch 216/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6555\n",
            "Epoch 217/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 0.6552\n",
            "Epoch 218/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7500 - loss: 0.6550\n",
            "Epoch 219/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6548\n",
            "Epoch 220/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7500 - loss: 0.6547\n",
            "Epoch 221/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7500 - loss: 0.6545\n",
            "Epoch 222/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7500 - loss: 0.6542\n",
            "Epoch 223/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7500 - loss: 0.6540\n",
            "Epoch 224/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7500 - loss: 0.6538\n",
            "Epoch 225/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6536\n",
            "Epoch 226/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6534\n",
            "Epoch 227/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7500 - loss: 0.6532\n",
            "Epoch 228/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6530\n",
            "Epoch 229/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7500 - loss: 0.6528\n",
            "Epoch 230/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7500 - loss: 0.6526\n",
            "Epoch 231/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6523\n",
            "Epoch 232/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7500 - loss: 0.6522\n",
            "Epoch 233/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7500 - loss: 0.6520\n",
            "Epoch 234/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7500 - loss: 0.6517\n",
            "Epoch 235/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7500 - loss: 0.6515\n",
            "Epoch 236/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7500 - loss: 0.6513\n",
            "Epoch 237/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6511\n",
            "Epoch 238/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6509\n",
            "Epoch 239/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6507\n",
            "Epoch 240/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6505\n",
            "Epoch 241/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6502\n",
            "Epoch 242/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6500\n",
            "Epoch 243/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6498\n",
            "Epoch 244/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6496\n",
            "Epoch 245/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7500 - loss: 0.6494\n",
            "Epoch 246/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6491\n",
            "Epoch 247/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6489\n",
            "Epoch 248/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6487\n",
            "Epoch 249/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.6485\n",
            "Epoch 250/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7500 - loss: 0.6483\n",
            "Epoch 251/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6481\n",
            "Epoch 252/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7500 - loss: 0.6478\n",
            "Epoch 253/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6476\n",
            "Epoch 254/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6474\n",
            "Epoch 255/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6472\n",
            "Epoch 256/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6470\n",
            "Epoch 257/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6467\n",
            "Epoch 258/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6465\n",
            "Epoch 259/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6463\n",
            "Epoch 260/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7500 - loss: 0.6460\n",
            "Epoch 261/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7500 - loss: 0.6458\n",
            "Epoch 262/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6456\n",
            "Epoch 263/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7500 - loss: 0.6454\n",
            "Epoch 264/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7500 - loss: 0.6451\n",
            "Epoch 265/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7500 - loss: 0.6449\n",
            "Epoch 266/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7500 - loss: 0.6447\n",
            "Epoch 267/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6444\n",
            "Epoch 268/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7500 - loss: 0.6442\n",
            "Epoch 269/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6440\n",
            "Epoch 270/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7500 - loss: 0.6438\n",
            "Epoch 271/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6435\n",
            "Epoch 272/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6433\n",
            "Epoch 273/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6431\n",
            "Epoch 274/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7500 - loss: 0.6428\n",
            "Epoch 275/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7500 - loss: 0.6426\n",
            "Epoch 276/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7500 - loss: 0.6424\n",
            "Epoch 277/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7500 - loss: 0.6421\n",
            "Epoch 278/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6419\n",
            "Epoch 279/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7500 - loss: 0.6417\n",
            "Epoch 280/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6414\n",
            "Epoch 281/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7500 - loss: 0.6412\n",
            "Epoch 282/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6410\n",
            "Epoch 283/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6407\n",
            "Epoch 284/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6405\n",
            "Epoch 285/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6402\n",
            "Epoch 286/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6400\n",
            "Epoch 287/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6397\n",
            "Epoch 288/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6395\n",
            "Epoch 289/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6393\n",
            "Epoch 290/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6390\n",
            "Epoch 291/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6388\n",
            "Epoch 292/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6385\n",
            "Epoch 293/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6383\n",
            "Epoch 294/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6381\n",
            "Epoch 295/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6379\n",
            "Epoch 296/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6376\n",
            "Epoch 297/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6373\n",
            "Epoch 298/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6371\n",
            "Epoch 299/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6369\n",
            "Epoch 300/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6366\n",
            "Epoch 301/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6364\n",
            "Epoch 302/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6361\n",
            "Epoch 303/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.6359\n",
            "Epoch 304/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6357\n",
            "Epoch 305/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.6354\n",
            "Epoch 306/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7500 - loss: 0.6351\n",
            "Epoch 307/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6349\n",
            "Epoch 308/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6347\n",
            "Epoch 309/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7500 - loss: 0.6344\n",
            "Epoch 310/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.6342\n",
            "Epoch 311/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.6339\n",
            "Epoch 312/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.6337\n",
            "Epoch 313/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7500 - loss: 0.6334\n",
            "Epoch 314/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6331\n",
            "Epoch 315/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 0.6329\n",
            "Epoch 316/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6327\n",
            "Epoch 317/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6324\n",
            "Epoch 318/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 0.6321\n",
            "Epoch 319/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6319\n",
            "Epoch 320/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6316\n",
            "Epoch 321/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6314\n",
            "Epoch 322/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6311\n",
            "Epoch 323/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6308\n",
            "Epoch 324/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6306\n",
            "Epoch 325/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6303\n",
            "Epoch 326/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6301\n",
            "Epoch 327/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6298\n",
            "Epoch 328/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6296\n",
            "Epoch 329/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6293\n",
            "Epoch 330/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6291\n",
            "Epoch 331/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6288\n",
            "Epoch 332/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7500 - loss: 0.6285\n",
            "Epoch 333/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.6283\n",
            "Epoch 334/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6280\n",
            "Epoch 335/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6277\n",
            "Epoch 336/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6275\n",
            "Epoch 337/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6273\n",
            "Epoch 338/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6270\n",
            "Epoch 339/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6267\n",
            "Epoch 340/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6264\n",
            "Epoch 341/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6262\n",
            "Epoch 342/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6259\n",
            "Epoch 343/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6257\n",
            "Epoch 344/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6254\n",
            "Epoch 345/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6251\n",
            "Epoch 346/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6249\n",
            "Epoch 347/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6246\n",
            "Epoch 348/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6244\n",
            "Epoch 349/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6241\n",
            "Epoch 350/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6238\n",
            "Epoch 351/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6236\n",
            "Epoch 352/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6233\n",
            "Epoch 353/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6230\n",
            "Epoch 354/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6227\n",
            "Epoch 355/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6225\n",
            "Epoch 356/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6222\n",
            "Epoch 357/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6219\n",
            "Epoch 358/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6217\n",
            "Epoch 359/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6214\n",
            "Epoch 360/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.6211\n",
            "Epoch 361/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6209\n",
            "Epoch 362/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6206\n",
            "Epoch 363/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6203\n",
            "Epoch 364/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6201\n",
            "Epoch 365/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7500 - loss: 0.6198\n",
            "Epoch 366/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6195\n",
            "Epoch 367/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6193\n",
            "Epoch 368/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6190\n",
            "Epoch 369/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6187\n",
            "Epoch 370/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6184\n",
            "Epoch 371/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.6182\n",
            "Epoch 372/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6179\n",
            "Epoch 373/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6176\n",
            "Epoch 374/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6173\n",
            "Epoch 375/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7500 - loss: 0.6171\n",
            "Epoch 376/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6168\n",
            "Epoch 377/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6165\n",
            "Epoch 378/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6162\n",
            "Epoch 379/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6159\n",
            "Epoch 380/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6157\n",
            "Epoch 381/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6154\n",
            "Epoch 382/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6151\n",
            "Epoch 383/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6149\n",
            "Epoch 384/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7500 - loss: 0.6146\n",
            "Epoch 385/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6143\n",
            "Epoch 386/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6140\n",
            "Epoch 387/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6138\n",
            "Epoch 388/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6135\n",
            "Epoch 389/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6132\n",
            "Epoch 390/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6129\n",
            "Epoch 391/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6126\n",
            "Epoch 392/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6124\n",
            "Epoch 393/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6121\n",
            "Epoch 394/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.6118\n",
            "Epoch 395/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6115\n",
            "Epoch 396/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6113\n",
            "Epoch 397/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6110\n",
            "Epoch 398/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6107\n",
            "Epoch 399/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6104\n",
            "Epoch 400/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6101\n",
            "Epoch 401/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6099\n",
            "Epoch 402/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6096\n",
            "Epoch 403/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6093\n",
            "Epoch 404/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.6090\n",
            "Epoch 405/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7500 - loss: 0.6088\n",
            "Epoch 406/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6085\n",
            "Epoch 407/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6082\n",
            "Epoch 408/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.6079\n",
            "Epoch 409/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6076\n",
            "Epoch 410/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.6073\n",
            "Epoch 411/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6070\n",
            "Epoch 412/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7500 - loss: 0.6068\n",
            "Epoch 413/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6065\n",
            "Epoch 414/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6062\n",
            "Epoch 415/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.6059\n",
            "Epoch 416/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6056\n",
            "Epoch 417/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6053\n",
            "Epoch 418/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6051\n",
            "Epoch 419/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6048\n",
            "Epoch 420/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6045\n",
            "Epoch 421/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6042\n",
            "Epoch 422/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6039\n",
            "Epoch 423/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6036\n",
            "Epoch 424/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6033\n",
            "Epoch 425/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6030\n",
            "Epoch 426/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.6028\n",
            "Epoch 427/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6025\n",
            "Epoch 428/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.6022\n",
            "Epoch 429/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6019\n",
            "Epoch 430/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.6016\n",
            "Epoch 431/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.6013\n",
            "Epoch 432/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6010\n",
            "Epoch 433/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6008\n",
            "Epoch 434/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7500 - loss: 0.6005\n",
            "Epoch 435/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.6002\n",
            "Epoch 436/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.5999\n",
            "Epoch 437/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.5996\n",
            "Epoch 438/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.5993\n",
            "Epoch 439/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.5990\n",
            "Epoch 440/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.5988\n",
            "Epoch 441/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.5985\n",
            "Epoch 442/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.5982\n",
            "Epoch 443/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.5979\n",
            "Epoch 444/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.5976\n",
            "Epoch 445/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.5973\n",
            "Epoch 446/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.5970\n",
            "Epoch 447/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.5968\n",
            "Epoch 448/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.5965\n",
            "Epoch 449/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7500 - loss: 0.5961\n",
            "Epoch 450/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.5958\n",
            "Epoch 451/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.5956\n",
            "Epoch 452/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.5953\n",
            "Epoch 453/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.5950\n",
            "Epoch 454/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.5947\n",
            "Epoch 455/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.5944\n",
            "Epoch 456/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7500 - loss: 0.5941\n",
            "Epoch 457/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7500 - loss: 0.5938\n",
            "Epoch 458/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.5935\n",
            "Epoch 459/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.5932\n",
            "Epoch 460/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7500 - loss: 0.5929\n",
            "Epoch 461/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7500 - loss: 0.5927\n",
            "Epoch 462/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.5924\n",
            "Epoch 463/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.5921\n",
            "Epoch 464/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.5918\n",
            "Epoch 465/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7500 - loss: 0.5915\n",
            "Epoch 466/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.5912\n",
            "Epoch 467/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.5909\n",
            "Epoch 468/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.5906\n",
            "Epoch 469/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.5903\n",
            "Epoch 470/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.5900\n",
            "Epoch 471/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.5897\n",
            "Epoch 472/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.5894\n",
            "Epoch 473/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.5892\n",
            "Epoch 474/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.5889\n",
            "Epoch 475/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.5886\n",
            "Epoch 476/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.5883\n",
            "Epoch 477/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7500 - loss: 0.5880\n",
            "Epoch 478/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.5877\n",
            "Epoch 479/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.5874\n",
            "Epoch 480/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7500 - loss: 0.5871\n",
            "Epoch 481/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.5868\n",
            "Epoch 482/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7500 - loss: 0.5865\n",
            "Epoch 483/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.5862\n",
            "Epoch 484/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.5859\n",
            "Epoch 485/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.5856\n",
            "Epoch 486/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7500 - loss: 0.5853\n",
            "Epoch 487/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.5851\n",
            "Epoch 488/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.5848\n",
            "Epoch 489/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7500 - loss: 0.5845\n",
            "Epoch 490/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.5842\n",
            "Epoch 491/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7500 - loss: 0.5839\n",
            "Epoch 492/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7500 - loss: 0.5836\n",
            "Epoch 493/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7500 - loss: 0.5833\n",
            "Epoch 494/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.5830\n",
            "Epoch 495/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.5827\n",
            "Epoch 496/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.5824\n",
            "Epoch 497/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7500 - loss: 0.5821\n",
            "Epoch 498/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.5818\n",
            "Epoch 499/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.5815\n",
            "Epoch 500/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7500 - loss: 0.5812\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.7500 - loss: 0.5809\n",
            "Multi-Layer Perceptron Accuracy: 75.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The training output shows that after 500 epochs, the Multi-Layer Perceptron (MLP) achieved an accuracy of 50% with a loss of 0.6954.\n",
        "- This means the model is only classifying correctly half of the time, which is equivalent to random guessing for a binary classification problem like XOR."
      ],
      "metadata": {
        "id": "34ekrPqV7wzL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Visualization:**"
      ],
      "metadata": {
        "id": "tObXacaf6z8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the XOR data points\n",
        "plt.scatter(X[:,0], X[:,1], c=y, cmap='bwr', marker='o')\n",
        "\n",
        "# Define the grid range\n",
        "xx, yy = np.meshgrid(np.arange(-0.5, 1.5, 0.01), np.arange(-0.5, 1.5, 0.01))\n",
        "Z = mlp_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot the decision boundary\n",
        "plt.contourf(xx, yy, Z, cmap='bwr', alpha=0.2)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "5awV0_Jo63H6",
        "outputId": "80a59d28-41a0-4626-cc5d-f0fda47fc7a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Interpretation:**\n",
        "\n",
        "1. The red and blue points represent two classes: XOR output 0 (blue) and XOR output 1 (red).\n",
        "2. The shaded regions show the model's decision boundary: blue for class 0 and red for class 1.\n",
        "3. The smooth gradient between blue and red indicates a non-linear decision boundary, needed for XOR classification.\n",
        "4. The model is partially correctly classifying the points, as the red points are in the red area and the blue points in the blue area.\n",
        "\n",
        "- This suggests the use of a multi-layer perceptron (MLP) to handle XOR's non-linear separability."
      ],
      "metadata": {
        "id": "CBHQ169I7Va4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2:**\n",
        "\n",
        "## A. Sentiment Analysis Twitter Airline"
      ],
      "metadata": {
        "id": "bXFElhZZ7-4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Loading and Preprocessing the Dataset"
      ],
      "metadata": {
        "id": "cVfkTl93_F6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- Importing the necessary libraries**"
      ],
      "metadata": {
        "id": "QLHEj0Ui8x8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import History\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "z6EdtUXG8yUi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- Loading the Dataset**"
      ],
      "metadata": {
        "id": "nTmKJMW-9c84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/Tweets.csv')\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "vZZd3AZY9fwS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "004c6dd0-111b-48b9-8f3b-94f5d6b8475f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
              "0  570306133677760513           neutral                        1.0000   \n",
              "1  570301130888122368          positive                        0.3486   \n",
              "2  570301083672813571           neutral                        0.6837   \n",
              "3  570301031407624196          negative                        1.0000   \n",
              "4  570300817074462722          negative                        1.0000   \n",
              "\n",
              "  negativereason  negativereason_confidence         airline  \\\n",
              "0            NaN                        NaN  Virgin America   \n",
              "1            NaN                     0.0000  Virgin America   \n",
              "2            NaN                        NaN  Virgin America   \n",
              "3     Bad Flight                     0.7033  Virgin America   \n",
              "4     Can't Tell                     1.0000  Virgin America   \n",
              "\n",
              "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
              "0                    NaN     cairdin                 NaN              0   \n",
              "1                    NaN    jnardino                 NaN              0   \n",
              "2                    NaN  yvonnalynn                 NaN              0   \n",
              "3                    NaN    jnardino                 NaN              0   \n",
              "4                    NaN    jnardino                 NaN              0   \n",
              "\n",
              "                                                text tweet_coord  \\\n",
              "0                @VirginAmerica What @dhepburn said.         NaN   \n",
              "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
              "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
              "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
              "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
              "\n",
              "               tweet_created tweet_location               user_timezone  \n",
              "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
              "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
              "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
              "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
              "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-676a8f5f-8394-495d-889a-28612eb8e73b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-676a8f5f-8394-495d-889a-28612eb8e73b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-676a8f5f-8394-495d-889a-28612eb8e73b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-676a8f5f-8394-495d-889a-28612eb8e73b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-84135035-ddd7-45bf-a879-eee994794798\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84135035-ddd7-45bf-a879-eee994794798')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-84135035-ddd7-45bf-a879-eee994794798 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 14640,\n  \"fields\": [\n    {\n      \"column\": \"tweet_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 779111158481835,\n        \"min\": 567588278875213824,\n        \"max\": 570310600460525568,\n        \"num_unique_values\": 14485,\n        \"samples\": [\n          567917894144770049,\n          567813976492417024,\n          569243676594941953\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"airline_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"airline_sentiment_confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16282995909867212,\n        \"min\": 0.335,\n        \"max\": 1.0,\n        \"num_unique_values\": 1023,\n        \"samples\": [\n          0.6723,\n          0.3551,\n          0.6498\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negativereason\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Damaged Luggage\",\n          \"Can't Tell\",\n          \"Lost Luggage\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negativereason_confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3304397596377297,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1410,\n        \"samples\": [\n          0.6677,\n          0.6622,\n          0.6905\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"airline\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Virgin America\",\n          \"United\",\n          \"American\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"airline_sentiment_gold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7701,\n        \"samples\": [\n          \"smckenna719\",\n          \"thisAnneM\",\n          \"jmspool\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negativereason_gold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Customer Service Issue\\nLost Luggage\",\n          \"Late Flight\\nCancelled Flight\",\n          \"Late Flight\\nFlight Attendant Complaints\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweet_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 44,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0,\n          1,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14427,\n        \"samples\": [\n          \"@JetBlue so technically I could drive to JFK now and put in. Request for tomorrow's flight?\",\n          \"@united why I won't check my carry on. Watched a handler throw this bag -- miss the conveyer belt -- sat there 10 min http://t.co/lyoocx5mSH\",\n          \"@SouthwestAir you guys are so clever \\ud83d\\ude03 http://t.co/qn5odUGFqK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_coord\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 832,\n        \"samples\": [\n          \"[40.04915451, -75.10364317]\",\n          \"[32.97609561, -96.53349238]\",\n          \"[26.37852293, -81.78472152]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_created\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 14247,\n        \"samples\": [\n          \"2015-02-23 07:40:55 -0800\",\n          \"2015-02-21 16:20:09 -0800\",\n          \"2015-02-21 21:33:21 -0800\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3081,\n        \"samples\": [\n          \"Oakland, California\",\n          \"Beverly Hills, CA\",\n          \"Austin, TX/NY, NY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_timezone\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"Helsinki\",\n          \"Eastern Time (US & Canada)\",\n          \"America/Detroit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- Pre-processing the data**"
      ],
      "metadata": {
        "id": "GiuIC4C69mpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant columns (text and sentiment)\n",
        "data = data[['text', 'airline_sentiment']]\n",
        "\n",
        "# Convert sentiment to binary classification: Positive = 1, Negative = 0\n",
        "data['airline_sentiment'] = data['airline_sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "\n",
        "# Tokenization and padding\n",
        "max_words = 5000  # Maximum number of words to use\n",
        "max_len = 100  # Maximum length of each sequence\n",
        "\n",
        "# Tokenizer for text data\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(data['text'])\n",
        "sequences = tokenizer.texts_to_sequences(data['text'])\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "X = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Labels\n",
        "y = data['airline_sentiment'].values\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Testing data shape: {X_test.shape}\")\n"
      ],
      "metadata": {
        "id": "K7J5opeQ905_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e098d7f2-9932-4f86-8cea-863d77e31fd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-32a1d55bdc87>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['airline_sentiment'] = data['airline_sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (11712, 100)\n",
            "Testing data shape: (2928, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Creating a Simple Feed-Forward Neural Network"
      ],
      "metadata": {
        "id": "lMs_W55w_Da0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(activation_function='relu'):\n",
        "    # Initialize a Sequential model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input layer and first hidden layer\n",
        "    model.add(Dense(128, input_shape=(max_len,), activation=activation_function))\n",
        "\n",
        "    # Second hidden layer\n",
        "    model.add(Dense(64, activation=activation_function))\n",
        "\n",
        "    # Output layer with sigmoid activation for binary classification\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model with Adam optimizer and binary crossentropy loss\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "3Hksl8H0-Y-z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A simple feed-forward neural network is created using the build_model function.\n",
        "- It includes an input layer, two hidden layers, and an output layer configured for binary classification."
      ],
      "metadata": {
        "id": "p8R0js75BasJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Training the Model Using Backpropagation"
      ],
      "metadata": {
        "id": "oWWGie-n_W3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using backpropagation\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saJoUv0k_Wm-",
        "outputId": "d4b143b2-ee6b-465b-b2a0-d499598585f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.4136 - val_accuracy: 0.8460 - val_loss: 0.4135\n",
            "Epoch 2/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.4116 - val_accuracy: 0.8449 - val_loss: 0.4090\n",
            "Epoch 3/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.4046 - val_accuracy: 0.8429 - val_loss: 0.4113\n",
            "Epoch 4/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 0.4167 - val_accuracy: 0.8429 - val_loss: 0.4117\n",
            "Epoch 5/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.4128 - val_accuracy: 0.8449 - val_loss: 0.4136\n",
            "Epoch 6/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8351 - loss: 0.4243 - val_accuracy: 0.8446 - val_loss: 0.4157\n",
            "Epoch 7/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8481 - loss: 0.3991 - val_accuracy: 0.8467 - val_loss: 0.4128\n",
            "Epoch 8/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8448 - loss: 0.4039 - val_accuracy: 0.8422 - val_loss: 0.4155\n",
            "Epoch 9/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.4077 - val_accuracy: 0.8405 - val_loss: 0.4149\n",
            "Epoch 10/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8520 - loss: 0.3954 - val_accuracy: 0.8467 - val_loss: 0.4107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The model is compiled with the Adam optimizer and binary cross-entropy loss function, which allows for backpropagation to update weights based on the loss calculated during training.\n",
        "- Training: The fit method runs the training process, which applies backpropagation to update the weights iteratively."
      ],
      "metadata": {
        "id": "qFDaFKrGB7vK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Experimenting with Different Activation Functions"
      ],
      "metadata": {
        "id": "srU1q5gr_gk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with different activation functions\n",
        "activation_functions = ['sigmoid', 'relu', 'tanh']\n",
        "histories = {}\n",
        "\n",
        "for activation in activation_functions:\n",
        "    print(f\"\\nTraining with {activation} activation function\\n\")\n",
        "\n",
        "    # Build and train the model\n",
        "    model = build_model(activation_function=activation)\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=10,\n",
        "                        batch_size=32,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        verbose=1)\n",
        "\n",
        "    # Store the training history for comparison\n",
        "    histories[activation] = history\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQfm5VCp_hg9",
        "outputId": "ab4cffea-b2b9-4aae-f576-2179b383c9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with sigmoid activation function\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.4281 - val_accuracy: 0.8432 - val_loss: 0.4092\n",
            "Epoch 2/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8378 - loss: 0.4269 - val_accuracy: 0.8446 - val_loss: 0.4138\n",
            "Epoch 3/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8295 - loss: 0.4334 - val_accuracy: 0.8432 - val_loss: 0.4142\n",
            "Epoch 4/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.4260 - val_accuracy: 0.8408 - val_loss: 0.4091\n",
            "Epoch 5/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.4155 - val_accuracy: 0.8422 - val_loss: 0.4076\n",
            "Epoch 6/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8339 - loss: 0.4252 - val_accuracy: 0.8446 - val_loss: 0.4083\n",
            "Epoch 7/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.4129 - val_accuracy: 0.8415 - val_loss: 0.4107\n",
            "Epoch 8/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8437 - loss: 0.4095 - val_accuracy: 0.8436 - val_loss: 0.4081\n",
            "Epoch 9/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8407 - loss: 0.4142 - val_accuracy: 0.8422 - val_loss: 0.4080\n",
            "Epoch 10/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.4120 - val_accuracy: 0.8436 - val_loss: 0.4080\n",
            "\n",
            "Training with relu activation function\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 19.0869 - val_accuracy: 0.7394 - val_loss: 5.6666\n",
            "Epoch 2/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7495 - loss: 5.0526 - val_accuracy: 0.7848 - val_loss: 4.2090\n",
            "Epoch 3/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7524 - loss: 3.1816 - val_accuracy: 0.6581 - val_loss: 3.7060\n",
            "Epoch 4/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7616 - loss: 2.3900 - val_accuracy: 0.8122 - val_loss: 2.5926\n",
            "Epoch 5/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7836 - loss: 1.5729 - val_accuracy: 0.5710 - val_loss: 2.8144\n",
            "Epoch 6/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7741 - loss: 1.3489 - val_accuracy: 0.7517 - val_loss: 1.6440\n",
            "Epoch 7/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 1.0910 - val_accuracy: 0.7630 - val_loss: 1.3216\n",
            "Epoch 8/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: 0.8982 - val_accuracy: 0.6783 - val_loss: 1.4057\n",
            "Epoch 9/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.7920 - val_accuracy: 0.7893 - val_loss: 1.2519\n",
            "Epoch 10/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.6396 - val_accuracy: 0.8023 - val_loss: 1.0295\n",
            "\n",
            "Training with tanh activation function\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8089 - loss: 0.4805 - val_accuracy: 0.8426 - val_loss: 0.4136\n",
            "Epoch 2/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8355 - loss: 0.4275 - val_accuracy: 0.8419 - val_loss: 0.4208\n",
            "Epoch 3/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8416 - loss: 0.4154 - val_accuracy: 0.8453 - val_loss: 0.4186\n",
            "Epoch 4/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8402 - loss: 0.4175 - val_accuracy: 0.8453 - val_loss: 0.4118\n",
            "Epoch 5/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.4136 - val_accuracy: 0.8432 - val_loss: 0.4109\n",
            "Epoch 6/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.4242 - val_accuracy: 0.8463 - val_loss: 0.4105\n",
            "Epoch 7/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.4211 - val_accuracy: 0.8429 - val_loss: 0.4129\n",
            "Epoch 8/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.4117 - val_accuracy: 0.8439 - val_loss: 0.4130\n",
            "Epoch 9/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8413 - loss: 0.4118 - val_accuracy: 0.8443 - val_loss: 0.4152\n",
            "Epoch 10/10\n",
            "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.4131 - val_accuracy: 0.8436 - val_loss: 0.4141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Evaluating the Model and Plotting Loss over Epochs"
      ],
      "metadata": {
        "id": "2Q5NhDvs_moa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the loss for each activation function\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for activation in activation_functions:\n",
        "    plt.plot(histories[activation].history['loss'], label=f'{activation} Loss')\n",
        "\n",
        "plt.title('Loss Over Epochs for Different Activation Functions')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the models on the test set\n",
        "for activation in activation_functions:\n",
        "    print(f\"\\nEvaluating model with {activation} activation function:\")\n",
        "    model = build_model(activation_function=activation)\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)  # Retrain\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "OXwWvZEj_r4N",
        "outputId": "1a3c9643-a808-448d-af0f-8765c01c1f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAIjCAYAAADWYVDIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABu6klEQVR4nO3dd3gU5d7G8XsT0huEGlqA0JEmCEIEQZAiFpCmcpQgokcB5XBUxAJYORYUFcGCIhYUxIP6KkWKgNIR8agQmgFC70kgkJDsvH9MdsmSQvpsNt/PdY07eXbKbzcbzJ15nmdshmEYAgAAAABIkrysLgAAAAAA3AkhCQAAAAAyISQBAAAAQCaEJAAAAADIhJAEAAAAAJkQkgAAAAAgE0ISAAAAAGRCSAIAAACATAhJAAAAAJAJIQkA3NDKlStls9k0f/78Yj3Pp59+qsaNG8vHx0fly5cv1nMVRExMjOrUqePSdvbsWd13332qVq2abDabxowZI0k6evSoBgwYoIoVK8pms2nq1KklXm9p5/jcrVy5ssTPvXfvXtlsNn388cclfu7S6OOPP5bNZtPevXutLgXwSIQkwI05/ie4efNmq0vJkzVr1qhfv36qWrWq/Pz8VKdOHT3wwAPav3+/1aVl4fhlMKflyy+/tLrEYhcbG6uYmBhFRUXpgw8+0Pvvv1+s55s0aZLLexwYGKjatWvrlltu0axZs5SSkpKn47z00kv6+OOP9eCDD+rTTz/V3XffLUn617/+pSVLlmj8+PH69NNP1atXr+J8OYUyffr0AoWBM2fOyN/fXzabTdu3by/x8xeFOXPmuF2AjYmJyfHfgsWLF1ta20svvaRvvvnG0hqAsqic1QUA8Axvv/22HnnkEdWrV0+jR49WRESEtm/frpkzZ2ru3LlauHChOnbsaHWZWTz88MO65pprsrR36NDBgmpK1sqVK2W32/Xmm2+qfv36JXbeGTNmKDg4WCkpKTp48KCWLFmie++9V1OnTtX333+vWrVqObf94IMPZLfbXfZfsWKFrr32Wk2cODFL+2233aZHH320RF5HYUyfPl2VKlVSTExMvvb76quvZLPZVK1aNX3++ed64YUXivT8nTt31vnz5+Xr61ug4+bFnDlz9OeffzqvADpERkbq/Pnz8vHxKbZz58bPz08zZ87M0t6yZUsLqrnkpZde0oABA9S3b1+X9rvvvlt33HGH/Pz8rCkM8HCEJACFtmbNGo0ZM0bXXXedFi9erMDAQOdzDz74oKKjozVgwAD99ddfqlChQonVde7cOQUFBeW6TadOnTRgwIASqsi9HDt2TJKKtJtdcnKyy/c/OwMGDFClSpWcX0+YMEGff/657rnnHg0cOFDr1693PpfdL8zHjh1T06ZNs20vyteSlpYmu91erIEhvz777DPddNNNioyM1Jw5cwocknLi5eUlf3//Ij1mXtlsNsvOLUnlypXTP/7xD8vOn1/e3t7y9va2ugzAY9HdDvAAv/32m3r37q3Q0FAFBwerW7duLr9oStLFixf17LPPqkGDBvL391fFihV13XXXaenSpc5tjhw5omHDhqlmzZry8/NTRESEbrvttiv2eX/++edls9k0e/bsLL8gR0VF6ZVXXtHhw4f13nvvSZJee+012Ww27du3L8uxxo8fL19fX50+fdrZtmHDBvXq1UthYWEKDAzU9ddfrzVr1rjs5+jKtW3bNt11112qUKGCrrvuujy9f1dis9k0atQoff7552rUqJH8/f3Vpk0brV69Osu2efleSGa3qX/961+qU6eO/Pz8VLNmTd1zzz06ceKEy3Z2u10vvviiatasKX9/f3Xr1k27d+922WbXrl3q37+/qlWrJn9/f9WsWVN33HGHEhIScnxNderUcV6JqVy5smw2myZNmuR8fvr06WrWrJn8/PxUvXp1jRw5UmfOnHE5RpcuXXTVVVfp119/VefOnRUYGKgnn3zySm9ntoYMGaL77rtPGzZscPlMZh6T5OgiGRcXpx9++MHZHcrRLdUwDL3zzjvOdoczZ85ozJgxqlWrlvz8/FS/fn29/PLLLleoHONhXnvtNU2dOlVRUVHy8/PTtm3bJJldEwcMGKDw8HD5+/urbdu2+u6771xeg6OONWvWaOzYsapcubKCgoLUr18/HT9+3OW9/+uvv7Rq1SpnrV26dLnie7R//379/PPPuuOOO3THHXcoLi5Oa9euzXbbzz77TO3atVNgYKAqVKigzp0768cff7zi+S8fkzRq1CgFBwcrOTk5yznuvPNOVatWTenp6ZKkb7/9Vn369FH16tXl5+enqKgoPf/8887nJfMz88MPP2jfvn3Oczu+vzmNSVqxYoU6deqkoKAglS9fXrfddluWroaOn//du3crJiZG5cuXV1hYmIYNG5Zt7fmV01it7GqOiYlRcHCwDh48qL59+yo4OFiVK1fWo48+6vJeSHJeyW3evLn8/f1VuXJl9erVy9nF2maz6dy5c5o9e7bz/XJc/ctpTFJ+fna3bdumrl27KjAwUDVq1NArr7yS5bW//fbbatasmfOz1LZtW82ZM6dA7yNQmnAlCSjl/vrrL3Xq1EmhoaF6/PHH5ePjo/fee09dunTRqlWr1L59e0nmLxGTJ0/Wfffdp3bt2ikxMVGbN2/Wli1bdOONN0qS+vfvr7/++kujR49WnTp1dOzYMS1dulT79+/PMnjeITk5WcuXL1enTp1Ut27dbLcZPHiw7r//fn3//fd64oknNGjQID3++OOaN2+eHnvsMZdt582bpx49ejivOK1YsUK9e/dWmzZtNHHiRHl5eWnWrFm64YYb9PPPP6tdu3Yu+w8cOFANGjTQSy+9JMMwrvj+JSUlZQkmkpyD/x1WrVqluXPn6uGHH5afn5+mT5+uXr16aePGjbrqqqvy9b04e/asOnXqpO3bt+vee+/V1VdfrRMnTui7777TgQMHXK6y/Oc//5GXl5ceffRRJSQk6JVXXtGQIUO0YcMGSVJqaqp69uyplJQUjR49WtWqVdPBgwf1/fff68yZMwoLC8v2dU+dOlWffPKJFixY4Oz+1qJFC0nmZ+XZZ59V9+7d9eCDD2rHjh2aMWOGNm3apDVr1rhc3Tl58qR69+6tO+64Q//4xz9UtWrVK77nObn77rv1/vvv68cff3R+JjNr0qSJPv30U/3rX/9SzZo19e9//1uS1Lp1a+fYpBtvvFH33HOPc5/k5GRdf/31OnjwoB544AHVrl1ba9eu1fjx43X48OEsY2NmzZqlCxcu6P7775efn5/Cw8P1119/KTo6WjVq1NATTzyhoKAgzZs3T3379tXXX3+tfv36uRxj9OjRqlChgiZOnKi9e/dq6tSpGjVqlObOnet870ePHq3g4GA99dRTkpSn9+2LL75QUFCQbr75ZgUEBCgqKkqff/55lm6szz77rCZNmqSOHTvqueeek6+vrzZs2KAVK1aoR48e+Tr/4MGD9c477+iHH37QwIEDXd7X//u//1NMTIzzasbHH3+s4OBgjR07VsHBwVqxYoUmTJigxMREvfrqq5Kkp556SgkJCTpw4IDeeOMNSVJwcHCOr3nZsmXq3bu36tWrp0mTJun8+fN6++23FR0drS1btmT5d2nQoEGqW7euJk+erC1btmjmzJmqUqWKXn755Su+v5Ky/Fvg4+OT489QbtLT09WzZ0+1b99er732mpYtW6YpU6YoKipKDz74oHO74cOH6+OPP1bv3r113333KS0tTT///LPWr1+vtm3b6tNPP3X+m33//fdLMv/wlJP8/OyePn1avXr10u23365BgwZp/vz5GjdunJo3b67evXtLMru7PvzwwxowYIAeeeQRXbhwQf/73/+0YcMG3XXXXfl+X4BSxQDgtmbNmmVIMjZt2pTjNn379jV8fX2NPXv2ONsOHTpkhISEGJ07d3a2tWzZ0ujTp0+Oxzl9+rQhyXj11VfzVePWrVsNScYjjzyS63YtWrQwwsPDnV936NDBaNOmjcs2GzduNCQZn3zyiWEYhmG3240GDRoYPXv2NOx2u3O75ORko27dusaNN97obJs4caIhybjzzjvzVPdPP/1kSMpxOXz4sHNbR9vmzZudbfv27TP8/f2Nfv36Odvy+r2YMGGCIcn473//m6Uux+t01NekSRMjJSXF+fybb75pSDL++OMPwzAM47fffjMkGV999VWeXndmjvfs+PHjzrZjx44Zvr6+Ro8ePYz09HRn+7Rp0wxJxkcffeRsu/766w1Jxrvvvlvg82Xm+Axmfk+HDh1qREZGumwXGRmZ7WdZkjFy5EiXtueff94ICgoydu7c6dL+xBNPGN7e3sb+/fsNwzCMuLg4Q5IRGhpqHDt2zGXbbt26Gc2bNzcuXLjgbLPb7UbHjh2NBg0aONscP6/du3d3+bz+61//Mry9vY0zZ84425o1a2Zcf/312b4POWnevLkxZMgQ59dPPvmkUalSJePixYvOtl27dhleXl5Gv379XL5/jpqvdH7H5+6nn35y7lOjRg2jf//+LtvNmzfPkGSsXr3a2ZacnJzleA888IARGBjo8t716dMny/fUMC59D2bNmuVsa9WqlVGlShXj5MmTzrbff//d8PLyMu655x5nm+Ozde+997ocs1+/fkbFihWznOtyQ4cOzfbfAcd7dPn7klvNjmM999xzLtu2bt3a5d+8FStWGJKMhx9+OEs9mb9XQUFBxtChQ7Ns4/i8xcXFGYZRsJ9dx7+1hmEYKSkpRrVq1Vy+17fddpvRrFmzrG8YUAbQ3Q4oxdLT0/Xjjz+qb9++qlevnrM9IiJCd911l3755RclJiZKMsed/PXXX9q1a1e2xwoICJCvr69Wrlzp0tXtSpKSkiRJISEhuW4XEhLirEUy/0L966+/as+ePc62uXPnys/PT7fddpskaevWrdq1a5fuuusunTx5UidOnNCJEyd07tw5devWTatXr84yqP+f//xnnmuXzPEwS5cuzbKEh4e7bNehQwe1adPG+XXt2rV12223acmSJUpPT8/X9+Lrr79Wy5Yts1yBkORy9UqShg0b5jImplOnTpKkv//+W5Kcf+VesmRJkXQrWrZsmVJTUzVmzBh5eV36X8SIESMUGhqqH374wWV7Pz8/DRs2rNDnlS5dUXB8porCV199pU6dOqlChQrOz8+JEyfUvXt3paenZ+ky2b9/f1WuXNn59alTp7RixQoNGjTIedXxxIkTOnnypHr27Kldu3bp4MGDLse4//77Xb6PnTp1Unp6erbdS/Pqf//7n/744w/deeedzrY777xTJ06c0JIlS5xt33zzjex2uyZMmODy/ZOyfrbywmazaeDAgVq4cKHOnj3rbJ87d65q1Kjh0qU1ICDAue54rzp16qTk5GTFxsbm+9yHDx/W1q1bFRMT4/Lz2KJFC914441auHBhln0u//nv1KmTTp486fJvT078/f2z/DswZcqUfNedWy2On1vJ/HfAZrNlmYBEKtj3Kr8/u8HBwS5jsHx9fdWuXTuXGsuXL68DBw5o06ZN+a4HKO0ISUApdvz4cSUnJ6tRo0ZZnmvSpInsdrvi4+MlSc8995zOnDmjhg0bqnnz5nrsscf0v//9z7m9n5+fXn75ZS1atEhVq1ZV586d9corr+jIkSO51uAIR1f6xTYpKcklSA0cOFBeXl7OLkiGYeirr75yjueR5Ax0Q4cOVeXKlV2WmTNnKiUlJcu4m5y6/OWkefPm6t69e5bl8sH6DRo0yLJvw4YNlZycrOPHj+fre7Fnzx5nF70rqV27tsvXjm6IjiBbt25djR07VjNnzlSlSpXUs2dPvfPOO7mOR8qN4xf5y1+Hr6+v6tWrl+UX/Ro1ahTZxAaOX8KvFLjzY9euXVq8eHGWz0/37t0lXZq8wuHyz8/u3btlGIaeeeaZLMdw/HJ7+TGu9D0riM8++0xBQUGqV6+edu/erd27d8vf31916tTR559/7txuz5498vLyynZii4IaPHiwzp8/7xyDdfbsWS1cuFADBw50+WX+r7/+Ur9+/RQWFqbQ0FBVrlzZ+Ut4QT6POX0WJfNnyvEHk8wK8957e3tn+Xcg8x9G8sMxvujyWjLXsWfPHlWvXj3LH2QKKr8/uzVr1swSxi6vcdy4cQoODla7du3UoEEDjRw5Mst4UMBTMSYJKCM6d+6sPXv26Ntvv9WPP/6omTNn6o033tC7776r++67T5I0ZswY3XLLLfrmm2+0ZMkSPfPMM5o8ebJWrFih1q1bZ3vc+vXrq1y5ci6B63IpKSnasWOH2rZt62yrXr26OnXqpHnz5unJJ5/U+vXrtX//fpexA46rRK+++qpatWqV7bEvH8+Q+a/ZniCn2auMTOOtpkyZopiYGOf39uGHH9bkyZO1fv161axZs1jrK8r3+88//5SkIp2O3G6368Ybb9Tjjz+e7fMNGzZ0+fry1+P4DD766KPq2bNntse4vN68fM/ywzAMffHFFzp37lyOs/qdPXs217E9hXHttdeqTp06mjdvnu666y793//9n86fP6/Bgwc7tzlz5oyuv/56hYaG6rnnnlNUVJT8/f21ZcsWjRs3LssV3+JS1O+9Q05Xdi6fiOFKdbiTvLxXTZo00Y4dO/T9999r8eLF+vrrrzV9+nRNmDBBzz77bEmVCliCkASUYpUrV1ZgYKB27NiR5bnY2Fh5eXm53HMmPDxcw4YN07Bhw3T27Fl17txZkyZNcoYkyRwU/O9//1v//ve/tWvXLrVq1UpTpkzRZ599lm0NQUFB6tq1q1asWKF9+/YpMjIyyzbz5s1TSkqKbr75Zpf2wYMH66GHHtKOHTs0d+5cBQYG6pZbbnGpRZJCQ0Odf/m3SnbdFHfu3KnAwEDnX4zz+r2IiopyBoKi0rx5czVv3lxPP/201q5dq+joaL377rv5niLa8f3bsWOHS7fB1NRUxcXFFev34dNPP5WkHMNIQURFRens2bMFrtvxHvj4+BTpa89Pd6pVq1bpwIEDeu6559SkSROX506fPq37779f33zzjf7xj38oKipKdrtd27Zty/EPC/k9v2ROiPDmm28qMTFRc+fOVZ06dXTttdc6n1+5cqVOnjyp//73v+rcubOzPS4ursDnzvxZvFxsbKwqVap0xSn+i4rjitTls8QVpgtlVFSUlixZolOnTuV6Nakg71dR/uwGBQVp8ODBGjx4sFJTU3X77bfrxRdf1Pjx4y2dsh0obnS3A0oxb29v9ejRQ99++63LNLBHjx7VnDlzdN111zm7rp08edJl3+DgYNWvX18pKSmSzNmqLly44LJNVFSUQkJCnNvk5Omnn5ZhGIqJidH58+ddnouLi9Pjjz+uiIgIPfDAAy7P9e/fX97e3vriiy/01Vdf6eabb3b5padNmzaKiorSa6+95jIewiHztMrFbd26ddqyZYvz6/j4eH377bfq0aOH834lef1e9O/fX7///rsWLFiQ5Tz5/Yt3YmKi0tLSXNqaN28uLy+vK37fsuPoavjWW2+51PLhhx8qISFBffr0yfcx82LOnDmaOXOmOnTooG7duhXZcQcNGqR169a5jNtxOHPmTJb37nJVqlRRly5d9N577+nw4cNZni/oZzAoKCjLL9w5cXS1e+yxxzRgwACXZcSIEWrQoIGzy13fvn3l5eWl5557LsvVm8zfz/ycXzL/oJGSkqLZs2dr8eLFGjRokMvzjqsSmc+Rmpqq6dOnZzlWUFBQnrrfRUREqFWrVpo9e7ZLrX/++ad+/PFH3XTTTXmuv7AiIyPl7e2dZQxbdq8vr/r37y/DMLK9IlOQ71Vx/Oxe/v8NX19fNW3aVIZh6OLFi/k+HlCacCUJKAU++ugjLV68OEv7I488ohdeeEFLly7Vddddp4ceekjlypXTe++9p5SUFJd7XjRt2lRdunRRmzZtFB4ers2bN2v+/PkaNWqUJPOqSLdu3TRo0CA1bdpU5cqV04IFC3T06FHdcccdudbXuXNnvfbaaxo7dqxatGihmJgYRUREKDY2Vh988IHsdrsWLlyY5UayVapUUdeuXfX6668rKSnJpfuOZN7YcubMmerdu7eaNWumYcOGqUaNGjp48KB++uknhYaG6v/+7/8K+rZKkn7++ecs4VAyB4c7psSWpKuuuko9e/Z0mQJckssvOHn9Xjz22GOaP3++Bg4cqHvvvVdt2rTRqVOn9N133+ndd99Vy5Yt81z/ihUrNGrUKA0cOFANGzZUWlqaPv30U3l7e6t///75fj8qV66s8ePH69lnn1WvXr106623aseOHZo+fbquueaaIrnZ5vz58xUcHKzU1FQdPHhQS5Ys0Zo1a9SyZUt99dVXhT5+Zo899pi+++473XzzzYqJiVGbNm107tw5/fHHH5o/f7727t3rMuV6dt555x1dd911at68uUaMGKF69erp6NGjWrdunQ4cOKDff/8933W1adNGM2bM0AsvvKD69eurSpUquuGGG7Jsl5KSoq+//lo33nhjjn+1v/XWW/Xmm2/q2LFjql+/vp566ik9//zz6tSpk26//Xb5+flp06ZNql69uiZPnpyv8ztcffXVzmOnpKRk+Vnt2LGjKlSooKFDh+rhhx+WzWbTp59+mm3ob9OmjebOnauxY8fqmmuuUXBwsMsV5MxeffVV9e7dWx06dNDw4cOdU4CHhYW53NeruIWFhWngwIF6++23ZbPZFBUVpe+//z7LeLT86Nq1q+6++2699dZb2rVrl3r16iW73a6ff/5ZXbt2df7b3KZNGy1btkyvv/66qlevrrp16zpvJ5BZcfzs9ujRQ9WqVVN0dLSqVq2q7du3a9q0aerTp0+Rjh0E3FKJz6cHIM8cU7zmtMTHxxuGYRhbtmwxevbsaQQHBxuBgYFG165djbVr17oc64UXXjDatWtnlC9f3ggICDAaN25svPjii0ZqaqphGIZx4sQJY+TIkUbjxo2NoKAgIywszGjfvr0xb968PNe7evVq47bbbjMqVapk+Pj4GLVr1zZGjBhh7N27N8d9PvjgA0OSERISYpw/fz7bbX777Tfj9ttvNypWrGj4+fkZkZGRxqBBg4zly5c7t7nS9NKXu9IU4BMnTnRuq4yppT/77DOjQYMGhp+fn9G6dess0wEbRt6+F4ZhGCdPnjRGjRpl1KhRw/D19TVq1qxpDB061Dhx4oRLfZdP7X35lMN///23ce+99xpRUVGGv7+/ER4ebnTt2tVYtmzZFd+D3N6zadOmGY0bNzZ8fHyMqlWrGg8++KBx+vRpl22uv/76fE0P7DifY/H39zdq1qxp3HzzzcZHH33kMk20Q2GnADcMw0hKSjLGjx9v1K9f3/D19TUqVapkdOzY0Xjttdecn3/H+5rTFPh79uwx7rnnHqNatWqGj4+PUaNGDePmm2825s+f79wmpyn7s5s++siRI0afPn2MkJAQl6mmL/f1118bkowPP/ww2+cNwzBWrlxpSDLefPNNZ9tHH31ktG7d2vDz8zMqVKhgXH/99cbSpUuveP6cpro2DMN46qmnDElG/fr1s61jzZo1xrXXXmsEBAQY1atXNx5//HFjyZIlWY539uxZ46677jLKly9vSHJ+f7ObTtswDGPZsmVGdHS0ERAQYISGhhq33HKLsW3bNpdtcvosXz5Ndk6GDh1qBAUF5brN8ePHjf79+xuBgYFGhQoVjAceeMD4888/s50CPLtjOWrMLC0tzXj11VeNxo0bG76+vkblypWN3r17G7/++qtzm9jYWKNz585GQECAIck5HXhOr60wP7uX/7y99957RufOnZ3/9kZFRRmPPfaYkZCQkOt7BXgCm2EUcjQjAHg4m82mkSNHatq0aVaXAgAASgBjkgAAAAAgE0ISAAAAAGRCSAIAAACATJjdDgCugKGbAACULVxJAgAAAIBMCEkAAAAAkInHd7ez2+06dOiQQkJCZLPZrC4HAAAAgEUMw1BSUpKqV68uL6+crxd5fEg6dOiQatWqZXUZAAAAANxEfHy8atasmePzHh+SQkJCJJlvRGhoqMXVAAAAALBKYmKiatWq5cwIOfH4kOToYhcaGkpIAgAAAHDFYThM3AAAAAAAmRCSAAAAACATQhIAAAAAZOLxY5IAAADgOdLT03Xx4kWry4Cb8vb2Vrly5Qp96x9CEgAAAEqFs2fP6sCBAzIMw+pS4MYCAwMVEREhX1/fAh+DkAQAAAC3l56ergMHDigwMFCVK1cu9JUCeB7DMJSamqrjx48rLi5ODRo0yPWGsbkhJAEAAMDtXbx4UYZhqHLlygoICLC6HLipgIAA+fj4aN++fUpNTZW/v3+BjsPEDQAAACg1uIKEKyno1SOXYxRBHQAAAADgMQhJAAAAAJAJIQkAAACwQExMjPr27Wt1GZKkOnXqaOrUqbluY7PZ9M0335RIPVZj4gYAAADAAm+++abbTGe+adMmBQUFFeoYMTExOnPmjEcEKUISAAAAYIGwsDCrS3CqXLmy1SW4FbrbAQAAoNQxDEPJqWmWLPm5+jN//nw1b95cAQEBqlixorp3765z585JytrdLikpSUOGDFFQUJAiIiL0xhtvqEuXLhozZoxzmzp16uiFF17QPffco+DgYEVGRuq7777T8ePHddtttyk4OFgtWrTQ5s2bXer4+uuv1axZM/n5+alOnTqaMmWKy/OXd7fbtWuXOnfuLH9/fzVt2lRLly7N+zcnB6tWrVK7du3k5+eniIgIPfHEE0pLS8vTe7Vy5Uq1a9dOQUFBKl++vKKjo7Vv375C15QTriQBAACg1Dl/MV1NJyyx5NzbnuupQN8r/xp9+PBh3XnnnXrllVfUr18/JSUl6eeff84xZI0dO1Zr1qzRd999p6pVq2rChAnasmWLWrVq5bLdG2+8oZdeeknPPPOM3njjDd19993q2LGj7r33Xr366qsaN26c7rnnHv3111+y2Wz69ddfNWjQIE2aNEmDBw/W2rVr9dBDD6lixYqKiYnJUofdbtftt9+uqlWrasOGDUpISHAJagVx8OBB3XTTTYqJidEnn3yi2NhYjRgxQv7+/po0aVKu71VaWpr69u2rESNG6IsvvlBqaqo2btxYrNPBE5IAAACAYnD48GGlpaXp9ttvV2RkpCSpefPm2W6blJSk2bNna86cOerWrZskadasWapevXqWbW+66SY98MADkqQJEyZoxowZuuaaazRw4EBJ0rhx49ShQwcdPXpU1apV0+uvv65u3brpmWeekSQ1bNhQ27Zt06uvvpptSFq2bJliY2O1ZMkS5/lfeukl9e7du8DvxfTp01WrVi1NmzZNNptNjRs31qFDhzRu3DhNmDAh1/fq1KlTSkhI0M0336yoqChJUpMmTQpcS14QkkqKYUjHtkl7f5HaP2B1NQAAAKVagI+3tj3X07Jz50XLli3VrVs3NW/eXD179lSPHj00YMAAVahQIcu2f//9ty5evKh27do528LCwtSoUaMs27Zo0cK5XrVqVUmu4cvRduzYMVWrVk3bt2/Xbbfd5nKM6OhoTZ06Venp6fL2dn0927dvV61atVwCWocOHfL0mnOyfft2dejQweXqT3R0tM6ePasDBw7k+l6Fh4crJiZGPXv21I033qju3btr0KBBioiIKFRNuWFMUklJSZLeu15a9Lh0YpfV1QAAAJRqNptNgb7lLFny2s3L29tbS5cu1aJFi9S0aVO9/fbbatSokeLi4gr12n18fFzeh5za7HZ7oc5Tkq70Xs2aNUvr1q1Tx44dNXfuXDVs2FDr168vtnoISSXFP1Sqc525vmORtbUAAACgRNhsNkVHR+vZZ5/Vb7/9Jl9fXy1YsCDLdvXq1ZOPj482bdrkbEtISNDOnTsLXUOTJk20Zs0al7Y1a9aoYcOGWa4iObaPj4/X4cOHnW2FDSRNmjTRunXrXMZjrVmzRiEhIapZs6akK79XrVu31vjx47V27VpdddVVmjNnTqFqyg3d7UpS4z7S3z9JOxZK0Q9bXQ0AAACK0YYNG7R8+XL16NFDVapU0YYNG3T8+PFsx9OEhIRo6NCheuyxxxQeHq4qVapo4sSJ8vLyKvQEBf/+9791zTXX6Pnnn9fgwYO1bt06TZs2TdOnT892++7du6thw4YaOnSoXn31VSUmJuqpp57K07kSEhK0detWl7aKFSvqoYce0tSpUzV69GiNGjVKO3bs0MSJEzV27Fh5eXnl+l7FxcXp/fff16233qrq1atrx44d2rVrl+65555CvS+5ISSVpIa9pIWPSvEbpHMnpKBKVlcEAACAYhIaGqrVq1dr6tSpSkxMVGRkpKZMmZLjBAivv/66/vnPf+rmm29WaGioHn/8ccXHx8vf379QdVx99dWaN2+eJkyYoOeff14RERF67rnnsp20QZK8vLy0YMECDR8+XO3atVOdOnX01ltvqVevXlc818qVK9W6dWuXtuHDh2vmzJlauHChHnvsMbVs2VLh4eEaPny4nn76aUm5v1dHjx5VbGysZs+erZMnTyoiIkIjR450Tl5RHGyGu9zmt5gkJiYqLCxMCQkJCg0Ntboc6d3rpCN/SH1nSK3usroaAACAUuHChQuKi4tT3bp1Cx0aSotz586pRo0amjJlioYPH251OaVGbp+VvGYDxiSVtEZ9zMfYH6ytAwAAAG7lt99+0xdffKE9e/Zoy5YtGjJkiCRlmZkOxY+QVNIaZVxe3bNCunjB2loAAADgVl577TW1bNlS3bt317lz5/Tzzz+rUiWGaJQ0xiSVtIiWUmgNKfGgFLdaatjD6ooAAADgBlq3bq1ff/3V6jIgriSVPJvt0tWkHXS5AwAAANwNIckKzpC0WCpFN/kCAAAAygJCkhXqdJJ8Q6SzR6TDv1ldDQAAAIBMCElWKOcn1e9mrscutLYWAAAAAC4ISVZpdJP5uGORtXUAAAAAcEFIskqDGyWbt3TsL+n0XqurAQAAAJCBkGSVwHApsqO5ztUkAAAAZNKlSxeNGTPG6jLKLEKSlZyz3DEuCQAAAEUrJiZGffv2tbqMUomQZCVHSNq7Rjp/2tpaAAAAUOxSU1OtLgF5QEiyUng9qXITyUiXdi2zuhoAAIDSwzCk1HPWLIaR5zK7dOmiUaNGacyYMapUqZJ69uwpSfrzzz/Vu3dvBQcHq2rVqrr77rt14sSJHI9js9n0zTffuLSVL19eH3/8cUHePUnSqlWr1K5dO/n5+SkiIkJPPPGE0tLSnM/Pnz9fzZs3V0BAgCpWrKju3bvr3LlzkqSVK1eqXbt2CgoKUvny5RUdHa19+/YVuBZ3U87qAsq8Rr2l49vNLnctBlpdDQAAQOlwMVl6qbo1537ykOQblOfNZ8+erQcffFBr1qyRJJ05c0Y33HCD7rvvPr3xxhs6f/68xo0bp0GDBmnFihXFVbWLgwcP6qabblJMTIw++eQTxcbGasSIEfL399ekSZN0+PBh3XnnnXrllVfUr18/JSUl6eeff5ZhGEpLS1Pfvn01YsQIffHFF0pNTdXGjRtls9lKpPaSQEiyWqObpF9el3Yvk9JSpXK+VlcEAACAItSgQQO98sorzq9feOEFtW7dWi+99JKz7aOPPlKtWrW0c+dONWzYsNhrmj59umrVqqVp06bJZrOpcePGOnTokMaNG6cJEybo8OHDSktL0+23367IyEhJUvPmzSVJp06dUkJCgm6++WZFRUVJkpo0aVLsNZckQpLVarSRgqpI545J+36Rom6wuiIAAAD35xNoXtGx6tz50KZNG5evf//9d/30008KDg7Osu2ePXtKJCRt375dHTp0cLn6Ex0drbNnz+rAgQNq2bKlunXrpubNm6tnz57q0aOHBgwYoAoVKig8PFwxMTHq2bOnbrzxRnXv3l2DBg1SREREsdddUhiTZDUvL6lRL3OdqcABAADyxmYzu7xZseSzW1lQkGvXvLNnz+qWW27R1q1bXZZdu3apc+fOObxcm4zLxkJdvHgxf+9ZPnh7e2vp0qVatGiRmjZtqrfffluNGjVSXFycJGnWrFlat26dOnbsqLlz56phw4Zav359sdVT0ghJ7qDRTebjjkX5GggIAACA0ufqq6/WX3/9pTp16qh+/fouy+WByqFy5co6fPiw8+tdu3YpOTm5wDU0adJE69atcwlea9asUUhIiGrWrCnJDGbR0dF69tln9dtvv8nX11cLFixwbt+6dWuNHz9ea9eu1VVXXaU5c+YUuB53Q0hyB3Wvl8oFSAnx0pE/rK4GAAAAxWjkyJE6deqU7rzzTm3atEl79uzRkiVLNGzYMKWnp2e7zw033KBp06bpt99+0+bNm/XPf/5TPj4+VzxXQkJClitW8fHxeuihhxQfH6/Ro0crNjZW3377rSZOnKixY8fKy8tLGzZs0EsvvaTNmzdr//79+u9//6vjx4+rSZMmiouL0/jx47Vu3Trt27dPP/74o3bt2uVR45IYk+QOfAPNsUg7fjCvJkW0sLoiAAAAFJPq1atrzZo1GjdunHr06KGUlBRFRkaqV69e8vLK/hrGlClTNGzYMHXq1EnVq1fXm2++qV9//fWK51q5cqVat27t0jZ8+HDNnDlTCxcu1GOPPaaWLVsqPDxcw4cP19NPPy1JCg0N1erVqzV16lQlJiYqMjJSU6ZMUe/evXX06FHFxsZq9uzZOnnypCIiIjRy5Eg98MADhX9z3ITNuLxzo4dJTExUWFiYEhISFBoaanU5OdvyqfTdKCmilfTAKqurAQAAcCsXLlxQXFyc6tatK39/f6vLgRvL7bOS12xAdzt30bCnJJt0eKuUcNDqagAAAIAyi5DkLoKrSLXames7meUOAAAAsAohyZ006m0+MhU4AAAAYBlCkjtxTAUet1pKSbK2FgAAAKCMIiS5k0oNpfAoKT1V2r3c6moAAACAMomQ5E5sNrrcAQAAABYjJLkbR5e7XUuk9DRrawEAAADKIEKSu6nVXgoIl86fluLXW10NAAAAUOYQktyNd7mMeyaJLncAAACABQhJ7sgxLin2B8kwrK0FAAAAbqlOnTqaOnWq1WV4JEKSO4rqJnn7SqfjpOM7rK4GAAAABdSlSxeNGTPG6jKcYmJi1LdvX6vLcHuEJHfkFyzVvd5c37HQ2loAAACAMoaQ5K6YChwAACBHhmEo+WKyJYuRx+EQMTExWrVqld58803ZbDbZbDbt3btX6enpGj58uOrWrauAgAA1atRIb775ZpZ9+/btq9dee00RERGqWLGiRo4cqYsXL7psl5ycrHvvvVchISGqXbu23n///UK9r6tWrVK7du3k5+eniIgIPfHEE0pLuzTj8vz589W8eXMFBASoYsWK6t69u86dOydJWrlypdq1a6egoCCVL19e0dHR2rdvX6HqsUo5qwtADhr1ln4YKx3YJJ09JgVXsboiAAAAt3E+7bzaz2lvybk33LVBgT6BV9zuzTff1M6dO3XVVVfpueeekyRVrlxZdrtdNWvW1FdffaWKFStq7dq1uv/++xUREaFBgwY59//pp58UERGhn376Sbt379bgwYPVqlUrjRgxwrnNlClT9Pzzz+vJJ5/U/Pnz9eCDD+r6669Xo0aN8v26Dh48qJtuukkxMTH65JNPFBsbqxEjRsjf31+TJk3S4cOHdeedd+qVV15Rv379lJSUpJ9//lmGYSgtLU19+/bViBEj9MUXXyg1NVUbN26UzWbLdx3ugJDkrkKrS9VbS4d+k3Yulq6+x+qKAAAAkA9hYWHy9fVVYGCgqlWr5mz39vbWs88+6/y6bt26WrdunebNm+cSkipUqKBp06bJ29tbjRs3Vp8+fbR8+XKXkHTTTTfpoYcekiSNGzdOb7zxhn766acChaTp06erVq1amjZtmmw2mxo3bqxDhw5p3LhxmjBhgg4fPqy0tDTdfvvtioyMlCQ1b95cknTq1CklJCTo5ptvVlRUlCSpSZMm+a7BXRCS3Fmjm8yQtGMRIQkAACCTgHIB2nDXBsvOXVjvvPOOPvroI+3fv1/nz59XamqqWrVq5bJNs2bN5O3t7fw6IiJCf/zxh8s2LVq0cK7bbDZVq1ZNx44dK1BN27dvV4cOHVyu/kRHR+vs2bM6cOCAWrZsqW7duql58+bq2bOnevTooQEDBqhChQoKDw9XTEyMevbsqRtvvFHdu3fXoEGDFBERUaBarMaYJHfW6Cbzcc9PUmqytbUAAAC4EZvNpkCfQEuWwnYh+/LLL/Xoo49q+PDh+vHHH7V161YNGzZMqampLtv5+Phkec12uz3f2xQVb29vLV26VIsWLVLTpk319ttvq1GjRoqLi5MkzZo1S+vWrVPHjh01d+5cNWzYUOvXry+WWoobIcmdVW0mhdWW0s5Lf6+0uhoAAADkk6+vr9LT013a1qxZo44dO+qhhx5S69atVb9+fe3Zs8eiCi9p0qSJ1q1b5zIxxZo1axQSEqKaNWtKMkNYdHS0nn32Wf3222/y9fXVggULnNu3bt1a48eP19q1a3XVVVdpzpw5Jf46igIhyZ3ZbJlmuWMqcAAAgNKmTp062rBhg/bu3asTJ07IbrerQYMG2rx5s5YsWaKdO3fqmWee0aZNm0qspoSEBG3dutVliY+P10MPPaT4+HiNHj1asbGx+vbbbzVx4kSNHTtWXl5e2rBhg1566SVt3rxZ+/fv13//+18dP35cTZo0UVxcnMaPH69169Zp3759+vHHH7Vr165SOy6JMUnurvFN0sb3zMkb7OmSl/eV9wEAAIBbePTRRzV06FA1bdpU58+fV1xcnB544AH99ttvGjx4sGw2m+6880499NBDWrSoZG79snLlSrVu3dqlbfjw4Zo5c6YWLlyoxx57TC1btlR4eLiGDx+up59+WpIUGhqq1atXa+rUqUpMTFRkZKSmTJmi3r176+jRo4qNjdXs2bN18uRJRUREaOTIkXrggQdK5DUVNZuR14neS6nExESFhYUpISFBoaGhVpeTf+kXpVeipJQEafhSqVY7qysCAAAocRcuXFBcXJzq1q0rf39/q8uBG8vts5LXbEB3O3fn7SM16G6u0+UOAAAAKHaEpNLAMctdLCEJAAAAKG6EpNKgfnfJq5x0Yod00vqZTwAAAABPRkgqDQLKS5HR5vqOkhnQBwAAAJRVhKTSwtHljnFJAACgDPPwOcdQBIriM2JpSFq9erVuueUWVa9eXTabTd98843L84ZhaMKECYqIiFBAQIC6d++uXbt2WVOs1Rz3S9q/Tko+ZW0tAAAAJczb27wNSmpqqsWVwN0lJydLknx8fAp8DEvvk3Tu3Dm1bNlS9957r26//fYsz7/yyit66623NHv2bNWtW1fPPPOMevbsqW3btpW9qR8rREpVr5KO/int+lFqeYfVFQEAAJSYcuXKKTAwUMePH5ePj4+8vOgQBVeGYSg5OVnHjh1T+fLlncG6ICwNSb1791bv3r2zfc4wDE2dOlVPP/20brvtNknSJ598oqpVq+qbb77RHXeUwZDQqLcZkmJ/ICQBAIAyxWazKSIiQnFxcdq3b5/V5cCNlS9fXtWqVSvUMSwNSbmJi4vTkSNH1L17d2dbWFiY2rdvr3Xr1uUYklJSUpSSkuL8OjExsdhrLTGNbpJWvyrtXi5dvCD5lLGraQAAoEzz9fVVgwYN6HKHHPn4+BTqCpKD24akI0eOSJKqVq3q0l61alXnc9mZPHmynn322WKtzTIRraSQCCnpsLT3l0s3mQUAACgjvLy8yt6wC5Q4j+vMOX78eCUkJDiX+Ph4q0sqOl5eUsNe5vqOH6ytBQAAAPBQbhuSHP0Ijx496tJ+9OjRXPsY+vn5KTQ01GXxKI37mI87FklMgQkAAAAUObcNSXXr1lW1atW0fPlyZ1tiYqI2bNigDh06WFiZxep0knyCzC53h7daXQ0AAADgcSwdk3T27Fnt3r3b+XVcXJy2bt2q8PBw1a5dW2PGjNELL7ygBg0aOKcAr169uvr27Wtd0Vbz8Zfq3yBt/z/zalL11lZXBAAAAHgUS0PS5s2b1bVrV+fXY8eOlSQNHTpUH3/8sR5//HGdO3dO999/v86cOaPrrrtOixcvZrBeoz5mSIpdKHV90upqAAAAAI9iMwzPHtiSmJiosLAwJSQkeM74pHMnpdfqS4ZdGvOHVL621RUBAAAAbi+v2cBtxyQhF0EVpVrXmus7FltbCwAAAOBhCEmlVeObzEemAgcAAACKFCGptGqUEZL2/iJdSLC2FgAAAMCDEJJKq4pRUqWGkj1N2r3M6moAAAAAj0FIKs0cV5NiF1pbBwAAAOBBCEmlmSMk7VoqpV+0thYAAADAQxCSSrOabaXASlJKgrRvrdXVAAAAAB6BkFSaeXlLjXqZ6zvocgcAAAAUBUJSaefocrdjoeTZ9wUGAAAASgQhqbSr10Uq5y+d2S8d22Z1NQAAAECpR0gq7XyDpHpdzXVmuQMAAAAKjZDkCRr1Nh8ZlwQAAAAUGiHJEzTsJckmHdoiJR62uhoAAACgVCMkeYKQquZ04JK0c5G1tQAAAAClHCHJUzi73BGSAAAAgMIgJHkKx1Tgf6+SUs5aWwsAAABQihGSPEXlxlKFulJ6irRnhdXVAAAAAKUWIclT2GyZbixLlzsAAACgoAhJnsQxLmnnYsmebm0tAAAAQClFSPIktTtI/uWl86ek+A1WVwMAAACUSoQkT+JdTmrY01znxrIAAABAgRCSPA1TgQMAAACFQkjyNFHdJC8f6eRu6fhOq6sBAAAASh1CkqfxD5XqdjbX6XIHAAAA5BshyRPR5Q4AAAAoMEKSJ3KEpPgN0tnj1tYCAAAAlDKEJE8UVlOKaCnJkHYtsboaAAAAoFQhJHmqRjeZj3S5AwAAAPKFkOSpHF3u9qyQLp63thYAAACgFCEkeapqLaTQmtLFZOnvVVZXAwAAAJQahCRPZbNlmuWOqcABAACAvCIkeTJHSNq5WLLbra0FAAAAKCUISZ6sTifJN0Q6e1Q6tMXqagAAAIBSgZDkycr5Sg26m+t0uQMAAADyhJDk6ZgKHAAAAMgXQpKna3CjZPOWjm2TTsVZXQ0AAADg9ghJni6gghTZ0VznahIAAABwRYSkssDZ5Y5xSQAAAMCVEJLKAsdU4PvWSsmnrK0FAAAAcHOEpLIgvK5UpalkpEu7l1ldDQAAAODWCEllheNqEl3uAAAAgFwRksqKRn3Mx13LpLQUa2sBAAAA3Bghqayo3loKriqlJkl7f7G6GgAAAMBtEZLKCi8vqWEvc52pwAEAAIAcEZLKksYZXe52LJIMw9paAAAAADdFSCpL6naWfAKlxAPSkf9ZXQ0AAADglghJZYlPgBR1g7lOlzsAAAAgW4SkssYxFXjsD9bWAQAAALgpQlJZ07CXJJvZ3S7hgNXVAAAAAG6HkFTWBFWSarU31+lyBwAAAGRBSCqLHF3udiy0tg4AAADADRGSyiLHVOBxP0sXEq2tBQAAAHAzhKSyqFIDqWJ9yX5R2rPc6moAAAAAt0JIKqucs9zR5Q4AAADIjJBUVjXK6HK3a4mUftHaWgAAAAA3Qkgqq2q1kwLCpQsJ0v71VlcDAAAAuA1CUlnl5Z1xzyQxyx0AAACQCSGpLGt8k/kY+4NkGNbWAgAAALgJQlJZVq+r5O0nndknHY+1uhoAAADALRCSyjK/YKne9eY6Xe4AAAAASYQkNHJ0uSMkAQAAABIhCY7JGw5ulpKOWlsLAAAA4AYISWVdaIRU/Wpzfedia2sBAAAA3AAhCZdmuWNcEgAAAEBIgi6NS/p7pZR6ztJSAAAAAKu5dUhKT0/XM888o7p16yogIEBRUVF6/vnnZXBPn6JVpalUvraUdsEMSgAAAEAZ5tYh6eWXX9aMGTM0bdo0bd++XS+//LJeeeUVvf3221aX5llsNqlRH3OdWe4AAABQxpWzuoDcrF27Vrfddpv69DF/ga9Tp46++OILbdy40eLKPFCj3tKGGebkDfZ0ycvb6ooAAAAAS7j1laSOHTtq+fLl2rlzpyTp999/1y+//KLevXvnuE9KSooSExNdFuRBZEfJP0xKPiEd2Gx1NQAAAIBl3DokPfHEE7rjjjvUuHFj+fj4qHXr1hozZoyGDBmS4z6TJ09WWFiYc6lVq1YJVlyKeftIDXqY6zt+sLYWAAAAwEJuHZLmzZunzz//XHPmzNGWLVs0e/Zsvfbaa5o9e3aO+4wfP14JCQnOJT4+vgQrLuUaZVyh27HI2joAAAAAC7n1mKTHHnvMeTVJkpo3b659+/Zp8uTJGjp0aLb7+Pn5yc/PryTL9Bz1u0tePtKJndKJ3VKl+lZXBAAAAJQ4t76SlJycLC8v1xK9vb1lt9stqsjD+YdJda4z17mxLAAAAMootw5Jt9xyi1588UX98MMP2rt3rxYsWKDXX39d/fr1s7o0z+W4sSxd7gAAAFBG2Qw3vjNrUlKSnnnmGS1YsEDHjh1T9erVdeedd2rChAny9fXN0zESExMVFhamhIQEhYaGFnPFHuDMfmlqc8nmJT26WwqqaHVFAAAAQJHIazZw65BUFAhJBfDuddKRP6S+M6RWd1ldDQAAAFAk8poN3Lq7HSzi7HLHuCQAAACUPYQkZOWYCnz3CuniBWtrAQAAAEoYIQlZRbSSQqpLF89JcautrgYAAAAoUYQkZGWzZbqxLF3uAAAAULYQkpA9x7iknYsl7ksFAACAMoSQhOzV7ST5BktJh6XDv1ldDQAAAFBiCEnIXjk/qX43c50bywIAAKAMISQhZ86pwAlJAAAAKDsISchZgx6SzVs6+qd0eq/V1QAAAAAlgpCEnAWGS7U7mOs7FltbCwAAAFBCCEnIHVOBAwAAoIwhJCF3jpC0b410/oylpQAAAAAlgZCE3FWMkio3luxp0u5lVlcDAAAAFDtCEq6MLncAAAAoQwhJuDLHVOC7lklpqdbWAgAAABQzQhKurEZbKaiylJJgjk0CAAAAPBghCVfm5SU17GWuc2NZAAAAeDhCEvLG0eVuxyLJMKytBQAAAChGhCTkTb0uUrkAKWG/dPRPq6sBAAAAig0hCXnjGyhFdTXX6XIHAAAAD0ZIQt4xFTgAAADKAEIS8q5hL0k26dBvUuIhq6sBAAAAigUhCXkXXEWqeY25Tpc7AAAAeChCEvLH2eWOkAQAAADPREhC/jTuYz7GrZJSkqytBQAAACgGhCTkT6WGUng9KT1V2rPC6moAAACAIkdIQv7YbK43lgUAAAA8DCEJ+ecISTsXS+lp1tYCAAAAFDFCEvKvVnspoIJ0/rQUv8HqagAAAIAiRUhC/nmXkxr0NNe5sSwAAAA8DCEJBeOcCnyhZBjW1gIAAAAUIUISCqZ+N8nbVzr1t3Rip9XVAAAAAEWGkISC8QuR6nY21+lyBwAAAA9CSELBObrcxRKSAAAA4DkISSi4hhkh6cAm6ewxa2sBAAAAigghCQUXVkOKaCXJkHYusboaAAAAoEgQklA4jhvLMi4JAAAAHoKQhMJpnBGS9vwkpSZbWwsAAABQBAhJKJyqV0lhtaS081LcKqurAQAAAAqNkITCsdkyzXL3g7W1AAAAAEWAkITCc4xL2rlYstutrQUAAAAoJEISCi8yWvILlc4dlw7+anU1AAAAQKEQklB45Xyl+t3N9R10uQMAAEDpRkhC0Wjcx3zcscjaOgAAAIBCIiShaNTvJnmVk47HSif3WF0NAAAAUGCEJBSNgApSZEdzfedia2sBAAAACoGQhKLTKKPLXexCa+sAAAAACoGQhKLTqJf5uH+dlHzK2loAAACAAiIkoehUqCNVaSYZ6dKupVZXAwAAABQIIQlFq3HGjWWZChwAAAClFCEJRatRb/Nx93IpLcXaWgAAAIACICShaEW0loKrSalnpb0/W10NAAAAkG+EJBQtL69LV5OY5Q4AAAClECEJRa+RY1zSIskwrK0FAAAAyCdCEope3c6ST5CUdEg6/LvV1QAAAAD5QkhC0fPxl+rfYK7voMsdAAAAShdCEoqHs8sdIQkAAAClCyEJxaNBT8nmJR35QzoTb3U1AAAAQJ4RklA8gipKta4113cssrYWAAAAIB8ISSg+jqnA6XIHAACAUqRAISk+Pl4HDhxwfr1x40aNGTNG77//fpEVBg/gGJe09xfpQoK1tQAAAAB5VKCQdNddd+mnn36SJB05ckQ33nijNm7cqKeeekrPPfdckRaIUqxSfaliA8l+Udq9zOpqAAAAgDwpUEj6888/1a5dO0nSvHnzdNVVV2nt2rX6/PPP9fHHHxdlfSjtGme6sSwAAABQChQoJF28eFF+fn6SpGXLlunWW2+VJDVu3FiHDx8uuupQ+jm63O36UUq/aG0tAAAAQB4UKCQ1a9ZM7777rn7++WctXbpUvXr1kiQdOnRIFStWLNICUcrVvEYKrGSOSdq31upqAAAAgCsqUEh6+eWX9d5776lLly6688471bJlS0nSd9995+yGV1QOHjyof/zjH6pYsaICAgLUvHlzbd68uUjPgWLk5S01NEM0Xe4AAABQGpQryE5dunTRiRMnlJiYqAoVKjjb77//fgUGBhZZcadPn1Z0dLS6du2qRYsWqXLlytq1a5fLOVEKNOotbf3MnAq812TJZrO6IgAAACBHBQpJ58+fl2EYzrCyb98+LViwQE2aNFHPnj2LrLiXX35ZtWrV0qxZs5xtdevWLbLjo4REdZXK+Utn9knHtklVm1ldEQAAAJCjAnW3u+222/TJJ59Iks6cOaP27dtrypQp6tu3r2bMmFFkxX333Xdq27atBg4cqCpVqqh169b64IMPct0nJSVFiYmJLgss5hsk1etirnNjWQAAALi5AoWkLVu2qFOnTpKk+fPnq2rVqtq3b58++eQTvfXWW0VW3N9//60ZM2aoQYMGWrJkiR588EE9/PDDmj17do77TJ48WWFhYc6lVq1aRVYPCqFRb/ORcUkAAABwczbDMIz87hQYGKjY2FjVrl1bgwYNUrNmzTRx4kTFx8erUaNGSk5OLpLifH191bZtW61de2lWtIcfflibNm3SunXrst0nJSVFKSkpzq8TExNVq1YtJSQkKDQ0tEjqQgEkHZGmNDLXx8ZKoRHW1gMAAIAyJzExUWFhYVfMBgW6klS/fn198803io+P15IlS9SjRw9J0rFjx4o0iERERKhp06YubU2aNNH+/ftz3MfPz0+hoaEuC9xASDWpRltzfedia2sBAAAAclGgkDRhwgQ9+uijqlOnjtq1a6cOHTpIkn788Ue1bt26yIqLjo7Wjh07XNp27typyMjIIjsHShBd7gAAAFAKFCgkDRgwQPv379fmzZu1ZMkSZ3u3bt30xhtvFFlx//rXv7R+/Xq99NJL2r17t+bMmaP3339fI0eOLLJzoAQ1usl8/HullHLW0lIAAACAnBRoTFJmBw4ckCTVrFmzSAq63Pfff6/x48dr165dqlu3rsaOHasRI0bkef+89jtECTAM6a1W0um90uDPpCa3WF0RAAAAypBiHZNkt9v13HPPKSwsTJGRkYqMjFT58uX1/PPPy263F7jo7Nx88836448/dOHCBW3fvj1fAQluxma7dDWJLncAAABwUwW6mexTTz2lDz/8UP/5z38UHR0tSfrll180adIkXbhwQS+++GKRFgkP0qi3tH66OXmDPV3y8ra6IgAAAMBFgULS7NmzNXPmTN16663OthYtWqhGjRp66KGHCEnIWe0Okn95KfmkFL9RiuxgdUUAAACAiwJ1tzt16pQaN26cpb1x48Y6depUoYuCB/P2kRqYU8Zrx0JrawEAAACyUaCQ1LJlS02bNi1L+7Rp09SiRYtCFwUPx1TgAAAAcGMF6m73yiuvqE+fPlq2bJnzHknr1q1TfHy8Fi7k6gCuoH53yctHOrlLOrFLqtTA6ooAAAAApwJdSbr++uu1c+dO9evXT2fOnNGZM2d0++2366+//tKnn35a1DXC0/iHSnU7met0uQMAAICbKfR9kjL7/fffdfXVVys9Pb2oDllo3CfJTW38QFr4qDmRw72Lra4GAAAAZUCx3icJKDTHuKT4DdK5E9bWAgAAAGRCSII1wmpK1VpIhl3aucTqagAAAAAnQhKs0+gm85FxSQAAAHAj+Zrd7vbbb8/1+TNnzhSmFpQ1jW+SVv1H2rNCunhe8gmwuiIAAAAgfyEpLCzsis/fc889hSoIZUi1FlJoDSnxoBS3WmrY0+qKAAAAgPyFpFmzZhVXHSiLbDZzAodNM80ud4QkAAAAuAHGJMFaznFJiyS73dpaAAAAABGSYLU610m+IdLZo9Kh36yuBgAAACAkwWLl/KT63cx1ZrkDAACAGyAkwXpMBQ4AAAA3QkiC9RrcKNm8pWPbpFNxVlcDAACAMo6QBOsFhkuRHc31nYutrQUAAABlHiEJ7qFRb/Mx9gdr6wAAAECZR0iCe3CEpH1rpfOnra0FAAAAZRohCe4hvJ5UuYlkpEu7llldDQAAAMowQhLch+Nq0g663AEAAMA6hCS4j8Z9zMddy6S0VGtrAQAAQJlFSIL7qH61FFRFSk2S9v1idTUAAAAoowhJcB9eXlKjXuZ6LDeWBQAAgDUISXAvjTK63O1YJBmGtbUAAACgTCIkwb3Uu14qFyAlHpCO/GF1NQAAACiDCElwLz4BUtQN5voOutwBAACg5BGS4H4a32Q+EpIAAABgAUIS3E+DnpJs0uHfpYSDVlcDAACAMoaQBPcTXFmq1c5c52oSAAAAShghCe6pkaPL3SJr6wAAAECZQ0iCe3KEpLjV0oVEa2sBAABAmUJIgnuq1EAKj5LsF6U9K6yuBgAAAGUIIQnuyWZjljsAAABYgpAE9+XocrdziZSeZm0tAAAAKDMISXBfNdtJAeHShTNS/HqrqwEAAEAZQUiC+/IuJzXsZa7H0uUOAAAAJYOQBPfWqLf5uGOhZBjW1gIAAIAygZAE9xZ1g+TtJ52Ok47HWl0NAAAAygBCEtybX7BU73pzff5w6dTf1tYDAAAAj0dIgvvrNlEKriod+0t6v6u0e5nVFQEAAMCDEZLg/qpdJd2/UqrR1pzp7vOB0i9vMEYJAAAAxYKQhNIhtLo0bKF09T2SYZeWTZK+ipFSzlpdGQAAADwMIQmlRzk/6Za3pD6vS14+0rZvpA97ME4JAAAARYqQhNLFZpOuGS7FfC8FVWGcEgAAAIocIQmlU+1rpQdWMU4JAAAARY6QhNKLcUoAAAAoBoQklG6MUwIAAEARIySh9GOcEgAAAIoQIQmeg3FKAAAAKAKEJHgWxikBAACgkAhJ8Dw5jlOKs7oyAAAAlAKEJHimbMcpdZF2L7e6MgAAALg5QhI8W5ZxSgOkX6YyTgkAAAA5IiTB82UZpzRRmj9MSj1ndWUAAABwQ4QklA2Xj1P6a4E080bGKQEAACALQhLKDsYpAQAAIA8ISSh7GKcEAACAXBCSUDYxTgkAAAA5ICSh7GKcEgAAALJBSELZxjglAAAAXIaQBEiMUwIAAIATIQlwcIxTan0345QAAADKsFIVkv7zn//IZrNpzJgxVpcCT1XOT7r1banPFMmrHOOUAAAAyqBSE5I2bdqk9957Ty1atLC6FHg6m0265j5pKOOUAAAAyqJSEZLOnj2rIUOG6IMPPlCFChWsLgdlRWQHxikBAACUQaUiJI0cOVJ9+vRR9+7dr7htSkqKEhMTXRagwBinBAAAUOa4fUj68ssvtWXLFk2ePDlP20+ePFlhYWHOpVatWsVcITwe45QAAADKFLcOSfHx8XrkkUf0+eefy9/fP0/7jB8/XgkJCc4lPj6+mKtEmcA4JQAAgDLDZhjuO8Dim2++Ub9+/eTt7e1sS09Pl81mk5eXl1JSUlyey05iYqLCwsKUkJCg0NDQ4i4ZZUHiIWnu3dLBzZLNS+o2UYp+xAxSAAAAcFt5zQZuHZKSkpK0b98+l7Zhw4apcePGGjdunK666qorHoOQhGKRliL98G/pt0/Nr5vdLt02TfINsrYuAAAA5Civ2aBcCdaUbyEhIVmCUFBQkCpWrJingAQUG8c4peqtpEXjpL/+K53YKQ3+TAqva3V1AAAAKAS3HpMEuLXLxykd/dMcp7RnhdWVAQAAoBDcurtdUaC7HUoE45QAAADcXl6zAVeSgKKQ7f2U7uV+SgAAAKUQIQkoKlnup/Rf6cMe3E8JAACglCEkAUWJcUoAAAClHiEJKA6RHaQHVkk12koXzkif9Zd+mSp59hBAAAAAj0BIAooL45QAAABKJUISUJwYpwQAAFDqEJKA4sY4JQAAgFKFkASUFMYpAQAAlAqEJKAkMU4JAADA7RGSgJLGOCUAAAC3RkgCrMA4JQAAALdFSAKslN04pTVvMk4JAADAQoQkwGqXj1NaOkH6ejjjlAAAACxCSALcweXjlP782hyndHqv1ZUBAACUOYQkwF0wTgkAAMAtEJIAd5N5nNL504xTAgAAKGGEJMAdMU4JAADAMoQkwF0xTgkAAMAShCTAnTFOCQAAoMQRkoDSgHFKAAAAJYaQBJQWjFMCAAAoEYQkoDRhnBIAAECxIyQBpQ3jlAAAAIoVIQkorRinBAAAUCwISUBpxjglAACAIkdIAko7xikBAAAUKUIS4AkYpwQAAFBkCEmAJ8lunNKSp6TEQ1ZXBgAAUGoQkgBPc/k4pXXTpKktpG9GSsd3WF0dAACA2yMkAZ7IMU5pyHwpMlqyX5S2fia900764k5p/3qrKwQAAHBbNsPw7PmCExMTFRYWpoSEBIWGhlpdDmCN+E3S2jel7d9LyviRr9Veih4jNewlefH3EgAA4Pnymg0ISUBZcmKXtPZt6fcvpPRUs61SQ6njw1KLQeYVKAAAAA9FSMpASAKykXRE2vCutOkjKSXBbAuJkK59UGoTI/mHWVoeAABAcSAkZSAkAbm4kChtmS2tmy4lZcyA5xcqtR0mXfuQFFLN2voAAACKECEpAyEJyIO0VOmPr6S1b0nHY802b1+pxWCzK17lhtbWBwAAUAQISRkISUA+2O3SriXSmjel/esyGm1S4z5S9CNSrXaWlgcAAFAYhKQMhCSggPZvMMPSjh8utdXuYM6I16AHM+IBAIBSh5CUgZAEFNLxnWY3vN+/NO+3JEmVG5vd8JoPlMr5WlsfAABAHhGSMhCSgCKSeFjaMEPaPEtKSTTbQqpLHR6Srh4q+fPzBQAA3BshKQMhCShiFxKkXz82Z8Q7e8Rs8wuTrrlXav+gFFLV0vIAAAByQkjKQEgCiklaivS/eWZXvBM7zTZvX6nlnWZXvEr1ra0PAADgMoSkDIQkoJjZ7dLORdIvU6UDGzMabVKTm81JHmq2tbA4AACASwhJGQhJQAnav94MSzsXXWqLjDanD2/QQ7LZLCsNAACAkJSBkARY4FistPZt6X9zL82IV6Wp2Q3vqv7MiAcAACxBSMpASAIslHhIWj9d2vyxlJpktoXWkDqMlK6+R/ILsbQ8AABQthCSMhCSADdw/oz06yxp/Qzp7FGzzT9MuuY+qf0/peAqlpYHAADKBkJSBkIS4EYuXjC74K19Szq522zz9pNa3SV1HC1VjLK2PgAA4NEISRkISYAbstulHT+Ykzwc3JzRaJOa3CJdN0aq0cbC4gAAgKciJGUgJAFuzDCk/eukNW9KOxdfaq/TyZwRr353ZsQDAABFhpCUgZAElBJHt5kz4v0xT7KnmW1Vmplh6arbJW8fa+sDAAClHiEpAyEJKGUSDpgTPPz6sZR61mwLrZlpRrxgS8sDAAClFyEpAyEJKKXOn5Y2fShteFc6d9xs8y8vtRshtXtACq5saXkAAKD0ISRlICQBpdzFC9LvX5gz4p3622wr5y+1GiJ1HCWF17O2PgAAUGoQkjIQkgAPYU+XYr83Z8Q7tMVss3lJTW41xy3VuNrS8gAAgPsjJGUgJAEexjCkfWvMsLR76aX2up3NsBTVjRnxAABAtghJGQhJgAc78qc5I96f8y/NiFe1uRmWmvWTvMtZWx8AAHArhKQMhCSgDDgTL62fLv06W7p4zmwLq50xI97dkm+QtfUBAAC3QEjKQEgCypDkU9LmD6X170rJJ8y2gApSu/vNJaiStfUBAABLEZIyEJKAMujieWnrHLMr3uk4s62cv9T6H1KHUVJ4XWvrAwAAliAkZSAkAWWYPV3a/p05ycPhrWabzUtq2tcct1S9lXW1AQCAEkdIykBIAiDDkPb+bIalPcsvtdfrYoalel2ZEQ8AgDKAkJSBkATAxZE/pDVvSX9+LRnpZlu1FmZYatqXGfEAAPBghKQMhCQA2TqzX1r3jrTlE+listlWPlLqOFpqNUTyDbS2PgAAUOQISRkISQBylXxK2jRT2vCulHzSbAsINyd5qN9dqn2tVM7P2hoBAECRICRlICQByJPUZGnr5+aMeGf2XWr3CZQiO0pRN5hjl6o0YfwSAACllEeEpMmTJ+u///2vYmNjFRAQoI4dO+rll19Wo0aN8nwMQhKAfElPk2K/l3Yskv7+STp71PX54GpSVNeM0NRFCq5iSZkAACD/PCIk9erVS3fccYeuueYapaWl6cknn9Sff/6pbdu2KSgoKE/HICQBKDDDkI5tk/askPb8JO1bI6VdcN2mavOM0NRVqt1B8gmwplYAAHBFHhGSLnf8+HFVqVJFq1atUufOnfO0DyEJQJG5eEGKX38pNB35n+vz5fzNoBR1gxmaql5F1zwAANxIXrNBqZrrNiEhQZIUHh6e4zYpKSlKSUlxfp2YmFjsdQEoI3z8zS529bpIN0o6e1yKW3UpNCUdMrvo/f2TtFRSUBVzW0fXvNAIK6sHAAB5VGquJNntdt166606c+aMfvnllxy3mzRpkp599tks7VxJAlCsDEM6vsMMSHtWSHt/uTS1uEOVpubkD1E3mJNBMM04AAAlyuO62z344INatGiRfvnlF9WsWTPH7bK7klSrVi1CEoCSlZYixW+8FJoObZWU6Z9bb19zenFHaKrWQvLysqpaAADKBI8KSaNGjdK3336r1atXq27duvnalzFJANxC8inp75UZoeknKSHe9fnAihld+TImgQjL+Y9BAACgYDwiJBmGodGjR2vBggVauXKlGjRokO9jEJIAuB3DkE7uNsPSnhXS3p+l1LOu21RqmDEBxA1SZLTkF2xNrQAAeBCPCEkPPfSQ5syZo2+//dbl3khhYWEKCMjbNLuEJABuL/2idGDTpdB0aItk2C897+Uj1WovRXUxQ1NEK8nL26pqAQAotTwiJNlymDp31qxZiomJydMxCEkASp3zp6W41ZdC05l9rs/7l8+YNa+r2T2vQqQVVQIAUOp4REgqCoQkAKXeqb8vTTMet1pKuezWBuFRl+7NVKeT5M+/dQAAZIeQlIGQBMCjpKeZ3fEcoenAJslIv/S8zVuqec2l0FT9asm7VN0SDwCAYkNIykBIAuDRLiSY92RyhKZTe1yf9wuT6na6FJrC61lTJwAAboCQlIGQBKBMOb3v0r2Z/l4lXTjj+nyFOpfuzVS3sxRQ3oIiAQCwBiEpAyEJQJllTzdvYrtnhRmc4jdI9rRLz9u8pBptzMBUr6tUs63k7WNZuQAAFDdCUgZCEgBkSEmS9q65FJpO7HR93jfkUte8el2lilFSDrOMAgBQGhGSMhCSACAHCQcuTTP+90rp/CnX58NqX7o3U93rpcBwK6oEAKDIEJIyEJIAIA/sdunI75dCU/wGKT010wY2qXprc/KHqBukmu2kcr6WlQsAQEEQkjIQkgCgAFLPSfvWXgpNx7e7Pu8TJNW57lJoqtSQrnkAALdHSMpASAKAIpB4yOySt+cnczzTueOuz4dUN8NSnWipfKQUVsNs42oTAMCNEJIyEJIAoIjZ7dKxvy7dm2nfWik9JZsNbVJwFSm0hhRaXQqraa6H1ZBCa5qPwdW42S0AoMQQkjIQkgCgmF08L+1fZ4amQ1vNCSESD+UQnC5j8zKDUliNjACVOUhlLMFVJS+vYn8ZAADPl9dswJ/vAACF4xNgdrWLuuFSm2FI505IiRmBKeGguZ5wUEo8aD4mHTLv25R0yFy0Kfvje5Uzu+45g1M2V6WCKjEmCgBQZAhJAICiZ7NJwZXNpXrr7Lexp5tjm7IEqAPmY+IhKemwGaQS9ptLTrx9zfDk6MZ3ebe+0BpSQAWCFAAgTwhJAABreHlLIdXMRW2y3yY9TTp75LIgdcg1VJ09ak5XfnqvueTEJzAjSGXq1nf5VSn/sGJ4oQCA0oaQBABwX97lzBATVlNS++y3SUs1u+tlF6AcV6WST0oXk6WTu80lJ74huXfrC6sh+QYVy0sFALgPQhIAoHQr5ytVqGMuObl4IaML38Gs3fsSD5lh6sIZKTVJOh5rLjnxD8u9W19odXOcFgCg1CIkAQA8n4+/VDHKXHKScjbrlShnqMp4TE2SLiSYy7G/cj5WYMXcu/VxDykAcGuEJAAAJMkvWKrc0FxyciEh9259CQeltPNm977kk9KR/+VwIMc9pBxjpGpJFSKlCnWl8Hrmejm/YnmZAIArIyQBAJBX/mHmUrVp9s8bhnT+dO7d+hz3kDp71FwO/ZbNgWxmeAqva3YjDK+XsV7XfGSCCQAoVoQkAACKis0mBYabS7Xm2W+T+R5SzitR8ebMfKf2Sqf+li6ey7jH1AFp789ZjxEQnjU4Oa5CBVdhqnMAKCRCEgAAJelK95AyDPP+UafipNNxmR7/NteTT0jnT0kHT0kHN2fd3yco4+pT3UuP4fXMEBVWy5wxEACQK/6lBADAndgyxisFV5FqZzPt+YXEjHtCZQSoU39nrO81rzxdPGdOKpHdxBJe5cyglDk4Oa5CVagj+QYW84sDgNLBZhiGYXURxSkxMVFhYWFKSEhQaGio1eUAAFB80lKlM/szBafMV6P2mmOhchMScVn3vUyPgeEl8hIAoDjlNRtwJQkAAE9RzleqVN9cLme3mzfdzbYb314pJUFKOmwu+9dm3d8/LOv4J8d6SITk5VXsLw8ASgpXkgAAKOscs/JdPv7JEabOHsl9/3L+UvnI7CeTKF+be0IBcBtcSQIAAHmTeVa+mm2yPp+anDH7Xjbd+M7sl9IuSCd2mEuWY3uZN9K9vPueY0yUX3CxvzwAyC9CEgAAyJ1voHlvqOzuD5V+0ZzC/PLxT6f+Nh8vJptB6sx+KW5V1v2DKmcNTo4wFVSJ6cwBWIKQBAAACs7bJ6ObXb2szxmGecPcnLrxnT9lTnd+7rh0YGPW/X1DpPA62V+FCq0heXkX+8sDUDYRkgAAQPGw2aSQauYS2SHr8xcSLpvG3HEVKs68yW5qknTkD3O5nJePVCFSCq4mBZSX/Mubj871CpnaMtb9w7hPFIA84V8KAABgDf8wqXorc7ncxQvSmX3Zz8Z3ep9kvyid3G0u+eEbclmYuvyxQvZt/mFcuQLKEEISAABwPz7+UuVG5nI5e7p5pelUnJR8Qjp/xpyd78IZc93xmHk9NcncNzXJXBLi81+TX5gUEJZ7mMoufPmFMUU6UMoQkgAAQOni5W1OLV6+dt73SU8zu/dlCVOnsw9VjufOn5EunjOPkZJgLtqfz4Jt5pUol26BFbKGqeza/EKZvAKwACEJAAB4Pu9yUlBFc8mvtFQzYGUOTlmuWmV3Jeu0lHZekmG2XTiT/3PbvLMGrLxeyfINJmABBURIAgAAyE05Xym4srnkV1pKzleortSWdkEy0s1ZAM+fyv+5vcrlMO6qvBmo/ELNAJbT4u2T/3MCHoKQBAAAUFzK+UkhVc0lvy6ez99Vq8xt6amSPc0cs5V8omC1+wRmDU45BqvQSzMIOpZyfgU7L+AGCEkAAADuyCfAXEIj8refYZgB60pXrVISM7oROh4zFsckFxeTzSXpcMHqL+d/hatVjufKZx/EfALoLgjLEJIAAAA8ic0m+QaaS2j1/O+fnmYGqJTLwpNzyaE9JdPzMszugmkXpHPHCvY6vHxyCFWZl/I5BzHfIEIWCoyQBAAAgEu8y0mB4eZSEHa7eTXqSqHKJVhdthh2815YhekuaPPOIViFmdOy53p1K8y8pxZTt5dZhCQAAAAUHS+vS0GjIAxDSj2XQ6hKzJgpMLerW2fM8VhGekbXwtMFfCG2S6Epc6jyC8nDEnppvZw/V7RKIUISAAAA3IfNJvkFm0tYjfzv7xyTlZBNl8Ezeeg2mGh2E5Rxqa0wvMqZYck3j6HKLzibthBzSncv78LVgjwjJAEAAMBzZB6TpXxOeuFw8cJlAetMRqg6I6WclVKSLi2pSa5fZ15kmFe1CnVFKxPf4EuBKceQlbkth+2YefCKCEkAAABAZj7+5hJcpeDHsNuli+cyhaazGRNiXB6msmnLHLwuJJrjsyQp9ay5FJa3b6YrVIW4uuUT5LHjtghJAAAAQFHz8roUJgorLSWHQJWf4JUpYKWnSsknzaVQbFm7BOZ0datilNS4T6HfipJCSAIAAADcWTk/cwmqVLjj2NPNoJRroMopeF22vZEuybg0XfyVRN1ASAIAAADgZry8CzfzoIORcR+s3K5cubSdlao0LprXUEIISQAAAADyzmaTfALMpTDjttyYZ460AgAAAIACIiQBAAAAQCaEJAAAAADIhJAEAAAAAJkQkgAAAAAgE2a3K0Gvb3xH59POy8vLW16yycvmlbHY5O3lLS95ycvLy3x0tGVs420ztzfbbPKymY/eNi9527zl7eXl3NZms8nbZu5ryziPzbG/zdvZlnlbm82Wcd7c2y4/prMt07aZj515fwAAAKA0ICSVoFl/fiZ5n7W6DOsYXpJskmyyySbzQmY264ZXRptNNl2+j4PtsuBlu9Sepc3RnnX7LMd0PGfLeT/nNi4tmb622XLcN+t/L+1r7pZTXZefz7HDpWeyrNmyq8G1lszVGIZyeE8vr998NGRkc+zs6peMy+pz3cP1nIbLFjnXbpPNrNnZnHPtNtmyqTdvtWe3fW7vqOvn59L5s9/W0ZD9OW3ZHiuno2azRY775uFIV3oNufzdo1B/Esl8YMPI/+65PJeno+W5+OyOVrg/BuV177z+zSm772vWz15ez5mHY+VYR96Ol5cjZrdbTv8OZX/EXLbN9TOfy89wlqJyPn9Ba730735Ox8lhvyt8WGz56FCUn89O7vXl40C5bZmHH4T81JGvinM5d34+fZe/htw/AzkWk2Mtl/bL4f8Wtszb5fP9zOVnMacj1QqrouHXdLviedwFIakElTvXQRfSkmXYDJn/gzVkyJBkl2xGxq+HhmTLaHOuX2q3ZWzrbMu8fUa7Lct+9su2vXybTMfMtJ8t877ZHM9my+cvMDa7czXznlmOUrjfM6yX/9/rCrcfAACAmws9cBUhCdn7bfTr2bYbhiHDyIgghpHxmBGhjMvWJdkztlcO7Yb5hPM4ducxDecfZrO0y/FHW0P2y8+Zsa0ur0tSut0uu+FY0pVuGLIbdmd7upEuI6PNbhhKt6fLLsej3flcut0uu+yyOx4NQ3YjPePRPHZGeRnR0qzH7ngjdKmujFcou2HPWDMLz/xazSa78ziXtrl0LOnS+3lpH+PSsy7bO97AS885j5Np3bmH4/vkUpOR6XuX+TU5z55tHZkrNAyXrTLtm+nzlun5Kz1nXPas8yQZXzn+CpXlmMbl7VmPk9tzmc98+Vq2+xmX1539a7MVqKbLL2jktFUOzxn52COP58nuu+P4mc9HZRlPZP9uZXOGTLvk/nry91fkkpZzbfm9cFXIi14Fku1psvuRyPXTkMvx83iCvB49h5+oAjZl05LdD1wO2+fnVRi5HCfn7Qq+bW4/UyVx/sIq6OctPzXk/2csH8cusvciL0fK/7lyPWouPwMF/8nNx89uPp6vHVIvz+d3B4QkN2Cz2TL9z9adf7kAAAAAPB+z2wEAAABAJoQkAAAAAMiEkAQAAAAAmRCSAAAAACATQhIAAAAAZEJIAgAAAIBMCEkAAAAAkAkhCQAAAAAyISQBAAAAQCaEJAAAAADIpFSEpHfeeUd16tSRv7+/2rdvr40bN1pdEgAAAAAP5fYhae7cuRo7dqwmTpyoLVu2qGXLlurZs6eOHTtmdWkAAAAAPJDNMAzD6iJy0759e11zzTWaNm2aJMlut6tWrVoaPXq0nnjiiSzbp6SkKCUlxfl1YmKiatWqpYSEBIWGhpZY3QAAAADcS2JiosLCwq6YDdz6SlJqaqp+/fVXde/e3dnm5eWl7t27a926ddnuM3nyZIWFhTmXWrVqlVS5AAAAADyAW4ekEydOKD09XVWrVnVpr1q1qo4cOZLtPuPHj1dCQoJziY+PL4lSAQAAAHiIclYXUNT8/Pzk5+dndRkAAAAASim3vpJUqVIleXt76+jRoy7tR48eVbVq1SyqCgAAAIAnc+uQ5OvrqzZt2mj58uXONrvdruXLl6tDhw4WVgYAAADAU7l9d7uxY8dq6NChatu2rdq1a6epU6fq3LlzGjZsWJ72d0zel5iYWJxlAgAAAHBzjkxwpQm+3T4kDR48WMePH9eECRN05MgRtWrVSosXL84ymUNOkpKSJIlZ7gAAAABIMjNCWFhYjs+7/X2SCstut+vQoUMKCQmRzWaztBbHPZvi4+O5ZxNKBJ85lCQ+byhpfOZQkvi8eQbDMJSUlKTq1avLyyvnkUdufyWpsLy8vFSzZk2ry3ARGhrKDxdKFJ85lCQ+byhpfOZQkvi8lX65XUFycOuJGwAAAACgpBGSAAAAACATQlIJ8vPz08SJE7nZLUoMnzmUJD5vKGl85lCS+LyVLR4/cQMAAAAA5AdXkgAAAAAgE0ISAAAAAGRCSAIAAACATAhJAAAAAJAJIakEvfPOO6pTp478/f3Vvn17bdy40eqS4IEmT56sa665RiEhIapSpYr69u2rHTt2WF0WypD//Oc/stlsGjNmjNWlwEMdPHhQ//jHP1SxYkUFBASoefPm2rx5s9VlwUOlp6frmWeeUd26dRUQEKCoqCg9//zzYu4zz0ZIKiFz587V2LFjNXHiRG3ZskUtW7ZUz549dezYMatLg4dZtWqVRo4cqfXr12vp0qW6ePGievTooXPnzlldGsqATZs26b333lOLFi2sLgUe6vTp04qOjpaPj48WLVqkbdu2acqUKapQoYLVpcFDvfzyy5oxY4amTZum7du36+WXX9Yrr7yit99+2+rSUIyYAryEtG/fXtdcc42mTZsmSbLb7apVq5ZGjx6tJ554wuLq4MmOHz+uKlWqaNWqVercubPV5cCDnT17VldffbWmT5+uF154Qa1atdLUqVOtLgse5oknntCaNWv0888/W10Kyoibb75ZVatW1Ycffuhs69+/vwICAvTZZ59ZWBmKE1eSSkBqaqp+/fVXde/e3dnm5eWl7t27a926dRZWhrIgISFBkhQeHm5xJfB0I0eOVJ8+fVz+rQOK2nfffae2bdtq4MCBqlKlilq3bq0PPvjA6rLgwTp27Kjly5dr586dkqTff/9dv/zyi3r37m1xZShO5awuoCw4ceKE0tPTVbVqVZf2qlWrKjY21qKqUBbY7XaNGTNG0dHRuuqqq6wuBx7syy+/1JYtW7Rp0yarS4GH+/vvvzVjxgyNHTtWTz75pDZt2qSHH35Yvr6+Gjp0qNXlwQM98cQTSkxMVOPGjeXt7a309HS9+OKLGjJkiNWloRgRkgAPNnLkSP3555/65ZdfrC4FHiw+Pl6PPPKIli5dKn9/f6vLgYez2+1q27atXnrpJUlS69at9eeff+rdd98lJKFYzJs3T59//rnmzJmjZs2aaevWrRozZoyqV6/OZ86DEZJKQKVKleTt7a2jR4+6tB89elTVqlWzqCp4ulGjRun777/X6tWrVbNmTavLgQf79ddfdezYMV199dXOtvT0dK1evVrTpk1TSkqKvL29LawQniQiIkJNmzZ1aWvSpIm+/vpriyqCp3vsscf0xBNP6I477pAkNW/eXPv27dPkyZMJSR6MMUklwNfXV23atNHy5cudbXa7XcuXL1eHDh0srAyeyDAMjRo1SgsWLNCKFStUt25dq0uCh+vWrZv++OMPbd261bm0bdtWQ4YM0datWwlIKFLR0dFZbmuwc+dORUZGWlQRPF1ycrK8vFx/Zfb29pbdbreoIpQEriSVkLFjx2ro0KFq27at2rVrp6lTp+rcuXMaNmyY1aXBw4wcOVJz5szRt99+q5CQEB05ckSSFBYWpoCAAIurgycKCQnJMuYtKChIFStWZCwcity//vUvdezYUS+99JIGDRqkjRs36v3339f7779vdWnwULfccotefPFF1a5dW82aNdNvv/2m119/Xffee6/VpaEYMQV4CZo2bZpeffVVHTlyRK1atdJbb72l9u3bW10WPIzNZsu2fdasWYqJiSnZYlBmdenShSnAUWy+//57jR8/Xrt27VLdunU1duxYjRgxwuqy4KGSkpL0zDPPaMGCBTp27JiqV6+uO++8UxMmTJCvr6/V5aGYEJIAAAAAIBPGJAEAAABAJoQkAAAAAMiEkAQAAAAAmRCSAAAAACATQhIAAAAAZEJIAgAAAIBMCEkAAAAAkAkhCQAAAAAyISQBAJCJzWbTN998Y3UZAAALEZIAAG4jJiZGNpsty9KrVy+rSwMAlCHlrC4AAIDMevXqpVmzZrm0+fn5WVQNAKAs4koSAMCt+Pn5qVq1ai5LhQoVJJld4WbMmKHevXsrICBA9erV0/z58132/+OPP3TDDTcoICBAFStW1P3336+zZ8+6bPPRRx+pWbNm8vPzU0REhEaNGuXy/IkTJ9SvXz8FBgaqQYMG+u6775zPnT59WkOGDFHlypUVEBCgBg0aZAl1AIDSjZAEAChVnnnmGfXv31+///67hgwZojvuuEPbt2+XJJ07d049e/ZUhQoVtGnTJn311VdatmyZSwiaMWOGRo4cqfvvv19//PGHvvvuO9WvX9/lHM8++6wGDRqk//3vf7rppps0ZMgQnTp1ynn+bdu2adGiRdq+fbtmzJihSpUqldwbAAAodjbDMAyriwAAQDLHJH322Wfy9/d3aX/yySf15JNPymaz6Z///KdmzJjhfO7aa6/V1VdfrenTp+uDDz7QuHHjFB8fr6CgIEnSwoULdcstt+jQoUOqWrWqatSooWHDhumFF17Itgabzaann35azz//vCQzeAUHB2vRokXq1auXbr31VlWqVEkfffRRMb0LAACrMSYJAOBWunbt6hKCJCk8PNy53qFDB5fnOnTooK1bt0qStm/frpYtWzoDkiRFR0fLbrdrx44dstlsOnTokLp165ZrDS1atHCuBwUFKTQ0VMeOHZMkPfjgg+rfv7+2bNmiHj16qG/fvurYsWOBXisAwD0RkgAAbiUoKChL97eiEhAQkKftfHx8XL622Wyy2+2SpN69e2vfvn1auHChli5dqm7dumnkyJF67bXXirxeAIA1GJMEAChV1q9fn+XrJk2aSJKaNGmi33//XefOnXM+v2bNGnl5ealRo0YKCQlRnTp1tHz58kLVULlyZQ0dOlSfffaZpk6dqvfff79QxwMAuBeuJAEA3EpKSoqOHDni0lauXDnn5AhfffWV2rZtq+uuu06ff/65Nm7cqA8//FCSNGTIEE2cOFFDhw7VpEmTdPz4cY0ePVp33323qlatKkmaNGmS/vnPf6pKlSrq3bu3kpKStGbNGo0ePTpP9U2YMEFt2rRRs2bNlJKSou+//94Z0gAAnoGQBABwK4sXL1ZERIRLW6NGjRQbGyvJnHnuyy+/1EMPPaSIiAh98cUXatq0qSQpMDBQS5Ys0SOPPKJrrrlGgYGB6t+/v15//XXnsYYOHaoLFy7ojTfe0KOPPqpKlSppwIABea7P19dX48eP1969exUQEKBOnTrpyy+/LIJXDgBwF8xuBwAoNWw2mxYsWKC+fftaXQoAwIMxJgkAAAAAMiEkAQAAAEAmjEkCAJQa9BAHAJQEriQBAAAAQCaEJAAAAADIhJAEAAAAAJkQkgAAAAAgE0ISAAAAAGRCSAIAAACATAhJAAAAAJAJIQkAAAAAMvl/zSR7qB8tgVgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating model with sigmoid activation function:\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4211\n",
            "Test Accuracy: 84.22%\n",
            "\n",
            "Evaluating model with relu activation function:\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7630 - loss: 1.0381\n",
            "Test Accuracy: 77.73%\n",
            "\n",
            "Evaluating model with tanh activation function:\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8392 - loss: 0.4224\n",
            "Test Accuracy: 84.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment Analysis Model Evaluation:**\n",
        "\n",
        "**1. Sigmoid Activation Function:**\n",
        "\n",
        "- Accuracy: 84.22%\n",
        "- Interpretation:\n",
        "The model successfully classified approximately 84.22% of the tweets as either positive or negative, indicating strong performance in identifying sentiments in the text. The low loss value (0.4211) suggests the model's predictions were quite accurate.\n",
        "\n",
        "**2. ReLU Activation Function:**\n",
        "\n",
        "- Accuracy: 77.73%\n",
        "- Interpretation:\n",
        "The ReLU model performed the weakest among the three, accurately classifying only 78% of sentiments. The higher loss (1.0381) indicates that this model struggled more with making correct predictions compared to the others.\n",
        "\n",
        "**3. Tanh Activation Function:**\n",
        "\n",
        "- Accuracy: 84.15%\n",
        "- Interpretation:\n",
        "The tanh model slightly outperformed the sigmoid model, achieving an accuracy of 84.15%. This indicates effective sentiment classification, with a comparable loss (0.4224), suggesting accurate predictions."
      ],
      "metadata": {
        "id": "VAzP4izcAiyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary:**\n",
        "\n",
        "- The sigmoid activation function proved to be the most effective for sentiment analysis in this context, closely followed by the tanh function. Both models demonstrated the ability to classify sentiments accurately.\n",
        "- In contrast, the ReLU function showed lower performance, highlighting its potential inadequacy for this type of text classification task.\n"
      ],
      "metadata": {
        "id": "F8mbx82WAzy_"
      }
    }
  ]
}